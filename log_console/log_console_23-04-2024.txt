Global seed set to 2024
wandb: Currently logged in as: 01133344 (cccvb). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240423_154719-org7b4lo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exp_search_model_type_dla_org7b4lo_crossentropy-multitarget-multitask_dream_tr_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17/runs/org7b4lo
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Experiments to be run:
* 
-d c10 --model.num_classes 10 --config.num_tasks 1 --loop.schedule 300 0 --config.framework_type crossentropy-multitarget-multitask --loop.num_loops 2 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --config.seed 2024 --datamodule.batch_size 220 --datamodule.vis.only_vis_at False --datamodule.vis.enable_vis_at 1 --loop.vis.image_reg.var.use_at True --loop.vis.image_reg.l2.use_at False --loop.test_at True --loop.vis.layerloss.deep_inversion.use_at True --datamodule.vis.optim.type adam  --datamodule.vis.image_type pixel --datamodule.vis.threshold 500 --loop.save.dreams --datamodule.vis.multitarget.enable --datamodule.vis.batch_size 220 --datamodule.vis.per_target 220 --loop.vis.generate_at 1 --datamodule.vis.standard_image_size 32 --loop.vis.image_reg.var.scale 0.001 --loop.vis.layerloss.deep_inversion.scale 10 --datamodule.vis.optim.kwargs.lr 0.05
 --model.type dla
* 
-d c10 --model.num_classes 10 --config.num_tasks 1 --loop.schedule 300 0 --config.framework_type crossentropy-multitarget-multitask --loop.num_loops 2 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --config.seed 2024 --datamodule.batch_size 220 --datamodule.vis.only_vis_at False --datamodule.vis.enable_vis_at 1 --loop.vis.image_reg.var.use_at True --loop.vis.image_reg.l2.use_at False --loop.test_at True --loop.vis.layerloss.deep_inversion.use_at True --datamodule.vis.optim.type adam  --datamodule.vis.image_type pixel --datamodule.vis.threshold 500 --loop.save.dreams --datamodule.vis.multitarget.enable --datamodule.vis.batch_size 220 --datamodule.vis.per_target 220 --loop.vis.generate_at 1 --datamodule.vis.standard_image_size 32 --loop.vis.image_reg.var.scale 0.001 --loop.vis.layerloss.deep_inversion.scale 10 --datamodule.vis.optim.kwargs.lr 0.05
 --model.type vgg
* 
-d c10 --model.num_classes 10 --config.num_tasks 1 --loop.schedule 300 0 --config.framework_type crossentropy-multitarget-multitask --loop.num_loops 2 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --config.seed 2024 --datamodule.batch_size 220 --datamodule.vis.only_vis_at False --datamodule.vis.enable_vis_at 1 --loop.vis.image_reg.var.use_at True --loop.vis.image_reg.l2.use_at False --loop.test_at True --loop.vis.layerloss.deep_inversion.use_at True --datamodule.vis.optim.type adam  --datamodule.vis.image_type pixel --datamodule.vis.threshold 500 --loop.save.dreams --datamodule.vis.multitarget.enable --datamodule.vis.batch_size 220 --datamodule.vis.per_target 220 --loop.vis.generate_at 1 --datamodule.vis.standard_image_size 32 --loop.vis.image_reg.var.scale 0.001 --loop.vis.layerloss.deep_inversion.scale 10 --datamodule.vis.optim.kwargs.lr 0.05
 --model.type custom-resnet34

Running experiment: exp_search_model_type_dla; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c10', datasampler_type='none', num_tasks=1, framework_type='crossentropy-multitarget-multitask', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], test_at=[True], save=Namespace(model=True, enable_checkpoint=False, dreams=True, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=2, schedule=[300, 0], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=[True], scale=10.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=[1], clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=[True], scale=0.001), l2=Namespace(use_at=[False], coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=None, onehot=Namespace(type='diagonal')), num_classes=10, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='dla', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=2.5, scale=2, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=0.0, ratio_gamma=1.0, scale_gamma=1.0, ratio_milestones=None, scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=220, multitarget=Namespace(enable=True, random=False), batch_size=220, optim=Namespace(type='adam', kwargs=Namespace(lr=0.05, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[500], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=[False], enable_vis_at=[1], standard_image_size=[32], decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py']"}
[34mWANDBO RUN ID: org7b4lo [0m
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: target-classic
	TASK SPLIT: SPLIT-CLASSIC-FILLLAST
	DREAM OBJECTIVE: OBJECTIVE-MULTITARGET-CROSSENTROPY
	MODEL TYPE: dla
	OVERLAY TYPE: CL-MODEL [0m
[32mINFO: Using loss DUMMY_LOSS__CrossEntropyLoss [0m
[32mMODEL TYPE: CLModel_DLA [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mVIS: Enabled multitarget visualization. Each batch will have multiple targets. [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name            ┃ Type               ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc       │ MulticlassAccuracy │      0 │
│ 1 │ train_acc_dream │ MulticlassAccuracy │      0 │
│ 2 │ _valid_accs     │ ModuleDict         │      0 │
│ 3 │ test_acc        │ MulticlassAccuracy │      0 │
│ 4 │ model           │ DLA                │ 32.6 M │
│ 5 │ _loss_f         │ DummyLoss          │      0 │
└───┴─────────────────┴────────────────────┴────────┘
Trainable params: 32.6 M                                                                                                                  
Non-trainable params: 0                                                                                                                   
Total params: 32.6 M                                                                                                                      
Total estimated model params size (MB): 130                                                                                               
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mTESTING TASK 0, loop 0 [0m
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│      test_loss_epoch      │    0.41367870569229126    │
│       test_step_acc       │    0.9279999732971191     │
└───────────────────────────┴───────────────────────────┘
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 274/274 0:00:22 • 0:00:00 12.50it/s  
Testing   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46   0:00:01 • 0:00:00 37.31it/s  
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[34mINFO: hooking model during visualization to - [33mDEEP INVERSION[34m - task: 0, loop 1 [0m
[34mINFO: For layerloss DeepInversionFeatureLoss used with default value: [36m'10.0'[34m  [0m
[34mINFO: hooking model during visualization to - [33mVARIATION IMAGE REGULARIZATION[34m - task: 0, loop 1 [0m
[34mDREAMING DURING TASK: 0, loop 1 [0m
[36mVIS: Visualization for targets: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9} [0m
[34mVIS: No hook to image after forward and backward pass. [0m
[34mVIS: Optimizer set during visualization config: [32mAdam (
Parameter Group 0
    amsgrad: False
    betas: [0.9, 0.999]
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    weight_decay: 0
) [0m
[32mVIS: Image size before (up/down)sample - torch.Size([220, 3, 41, 41]) [0m
[32mVIS: Image size after (up/down)sample - torch.Size([220, 3, 32, 32]) [0m
[36mVIS: ENABLE DREAM TRANSFORMS [0m
[32mVIS: Current in use image size - torch.Size([220, 3, 32, 32]) [0m
[36mVIS: Number of images to visualize (may change in fast-dev-run): 2200; batch size: 220; per target: 220; batches to be generated: 10 [0m
[36mVIS: Using multitarget visualization [0m
[34mTime generating features: 00:10:15 [0m
[34mDREAMING END [0m
[34mSTARTING TASK 0, loop 1 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[31mINFO: SKIPPING ANY TRAINING at loop 1 [0m
[34mENDING TASK 0, loop 1 [0m
[34mTESTING TASK 0, loop 1 [0m
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│      test_loss_epoch      │    0.41367870569229126    │
│       test_step_acc       │    0.9279999732971191     │
└───────────────────────────┴───────────────────────────┘
Iteration: ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 500/500 0:01:01 • 0:00:00 8.20it/s   
                                                                                         
                                                                                         
Testing    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46   0:00:01 • 0:00:00 37.14it/s  
[34mINFO: Generated current run name: d23-04-2024_h17-49-54_org7b4lo [0m
[31mWARNING: At loop 2 selected last epoch per task "0" because list index out of range. [0m
[31mWARNING: At loop 2 selected last epoch per task "0" because list index out of range. [0m

End of training.
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 10 dimensions.
INFO: Plot model_save/test/ClModel/DLA/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h17-49-54_org7b4lo/plots/std-mean_idx10
INFO: Plot model_save/test/ClModel/DLA/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h17-49-54_org7b4lo/plots/distance_class_idx10
INFO: Plot model_save/test/ClModel/DLA/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h17-49-54_org7b4lo/plots/mean_distance_idx10
INFO: Plot model_save/test/ClModel/DLA/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h17-49-54_org7b4lo/plots/mean_dist_matrix_idx10
wandb: - 1.889 MB of 1.889 MB uploadedwandb: \ 1.889 MB of 1.889 MB uploadedwandb: | 1.889 MB of 1.889 MB uploadedwandb: / 1.902 MB of 1.932 MB uploadedwandb: - 1.902 MB of 1.932 MB uploadedwandb: \ 1.932 MB of 1.932 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: dream_loss/run_0/multi_target_0 ▇████▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▂▃▂▃▃▂▂▂▂▂▂▂▂▁▂▁▂▁▁
wandb: dream_loss/run_0/multi_target_1 ▆▇███▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁
wandb: dream_loss/run_0/multi_target_2 ▆▇▇█▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▂▁
wandb: dream_loss/run_0/multi_target_3 ▇███▇▇▆▆▆▅▅▅▄▄▄▄▃▃▄▃▃▃▃▂▂▃▂▂▂▂▂▁▂▂▁▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_4 ▇▇▇█▇▇▆▆▅▅▅▄▃▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_5 ▆▇██▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb: dream_loss/run_0/multi_target_6 ▇███▇▇▆▆▅▅▅▄▄▄▄▄▃▄▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_7 ▇▇███▇▆▆▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_8 ▆▇██▇▇▇▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_9 ▄▇███▇▆▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁
wandb:                           epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          stats/collect_accuracy ▂▁█▄▃▃▂▃▂▂▁▁
wandb:              stats/collect_loss ▄▆▁█▅▅▇▃█▇██
wandb:                 test_loss_epoch ▁▁
wandb:                  test_loss_step ▄▁▅▃▆▇▃▆▄▅▃▄▃▃▅▄▅▄▅▄▄▇▅▃▇▅▃▅▄▅▄▃▃▆▄▄█▃▅▅
wandb:                   test_step_acc ▁▁
wandb:  train_loss/classification_loss █▄▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_loss/total █▄▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  train_step_acc ▁▄▆▇▇▇██████████████████████████████████
wandb:             trainer/global_step ▁▂▂▃▄▄▅▆▆▇▇▁███████████████████████████▁
wandb:              val_last_step_loss ▃▄▇▁▁▂█▂▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  valid_step_acc ▃▃▁▇▇▇▄▆███▇████▇▇██████████████████████
wandb: 
wandb: Run summary:
wandb: dream_loss/run_0/multi_target_0 5.35047
wandb: dream_loss/run_0/multi_target_1 6.05037
wandb: dream_loss/run_0/multi_target_2 4.91618
wandb: dream_loss/run_0/multi_target_3 6.24824
wandb: dream_loss/run_0/multi_target_4 5.7257
wandb: dream_loss/run_0/multi_target_5 5.77856
wandb: dream_loss/run_0/multi_target_6 6.52003
wandb: dream_loss/run_0/multi_target_7 5.20735
wandb: dream_loss/run_0/multi_target_8 6.3065
wandb: dream_loss/run_0/multi_target_9 6.59
wandb:                           epoch 0
wandb:          stats/collect_accuracy 0.92538
wandb:              stats/collect_loss 0.59256
wandb:                 test_loss_epoch 0.41368
wandb:                  test_loss_step 0.43256
wandb:                   test_step_acc 0.928
wandb:  train_loss/classification_loss 0.00225
wandb:                train_loss/total 0.00225
wandb:                  train_step_acc 0.99994
wandb:             trainer/global_step 2420
wandb:              val_last_step_loss 0.41368
wandb:                  valid_step_acc 0.928
wandb: 
wandb: 🚀 View run exp_search_model_type_dla_org7b4lo_crossentropy-multitarget-multitask_dream_tr_ at: https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17/runs/org7b4lo
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17
wandb: Synced 6 W&B file(s), 15 media file(s), 84 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240423_154719-org7b4lo/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240423_175132-lxb5cypv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exp_search_model_type_vgg_lxb5cypv_crossentropy-multitarget-multitask_dream_tr_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17/runs/lxb5cypv
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: exp_search_model_type_dla; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: exp_search_model_type_vgg; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c10', datasampler_type='none', num_tasks=1, framework_type='crossentropy-multitarget-multitask', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], test_at=[True], save=Namespace(model=True, enable_checkpoint=False, dreams=True, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=2, schedule=[300, 0], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=[True], scale=10.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=[1], clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=[True], scale=0.001), l2=Namespace(use_at=[False], coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=None, onehot=Namespace(type='diagonal')), num_classes=10, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='vgg', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=2.5, scale=2, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=0.0, ratio_gamma=1.0, scale_gamma=1.0, ratio_milestones=None, scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=220, multitarget=Namespace(enable=True, random=False), batch_size=220, optim=Namespace(type='adam', kwargs=Namespace(lr=0.05, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[500], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=[False], enable_vis_at=[1], standard_image_size=[32], decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py']"}
[34mWANDBO RUN ID: lxb5cypv [0m
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: target-classic
	TASK SPLIT: SPLIT-CLASSIC-FILLLAST
	DREAM OBJECTIVE: OBJECTIVE-MULTITARGET-CROSSENTROPY
	MODEL TYPE: vgg
	OVERLAY TYPE: CL-MODEL [0m
[32mINFO: Using loss DUMMY_LOSS__CrossEntropyLoss [0m
[32mMODEL TYPE: CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mVIS: Enabled multitarget visualization. Each batch will have multiple targets. [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name            ┃ Type               ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc       │ MulticlassAccuracy │      0 │
│ 1 │ train_acc_dream │ MulticlassAccuracy │      0 │
│ 2 │ _valid_accs     │ ModuleDict         │      0 │
│ 3 │ test_acc        │ MulticlassAccuracy │      0 │
│ 4 │ model           │ VGG                │  9.2 M │
│ 5 │ _loss_f         │ DummyLoss          │      0 │
└───┴─────────────────┴────────────────────┴────────┘
Trainable params: 9.2 M                                                                                                                   
Non-trainable params: 0                                                                                                                   
Total params: 9.2 M                                                                                                                       
Total estimated model params size (MB): 36                                                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mTESTING TASK 0, loop 0 [0m
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│      test_loss_epoch      │    0.6302027106285095     │
│       test_step_acc       │     0.894599974155426     │
└───────────────────────────┴───────────────────────────┘
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 274/274 0:00:05 • 0:00:00 48.22it/s  
Testing   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46   0:00:00 • 0:00:00 78.42it/s  
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[34mINFO: hooking model during visualization to - [33mDEEP INVERSION[34m - task: 0, loop 1 [0m
[34mINFO: For layerloss DeepInversionFeatureLoss used with default value: [36m'10.0'[34m  [0m
[34mINFO: hooking model during visualization to - [33mVARIATION IMAGE REGULARIZATION[34m - task: 0, loop 1 [0m
[34mDREAMING DURING TASK: 0, loop 1 [0m
[36mVIS: Visualization for targets: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9} [0m
[34mVIS: No hook to image after forward and backward pass. [0m
[34mVIS: Optimizer set during visualization config: [32mAdam (
Parameter Group 0
    amsgrad: False
    betas: [0.9, 0.999]
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    weight_decay: 0
) [0m
[32mVIS: Image size before (up/down)sample - torch.Size([220, 3, 41, 41]) [0m
[32mVIS: Image size after (up/down)sample - torch.Size([220, 3, 32, 32]) [0m
[36mVIS: ENABLE DREAM TRANSFORMS [0m
[32mVIS: Current in use image size - torch.Size([220, 3, 32, 32]) [0m
[36mVIS: Number of images to visualize (may change in fast-dev-run): 2200; batch size: 220; per target: 220; batches to be generated: 10 [0m
[36mVIS: Using multitarget visualization [0m
[34mTime generating features: 00:01:52 [0m
[34mDREAMING END [0m
[34mSTARTING TASK 0, loop 1 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[31mINFO: SKIPPING ANY TRAINING at loop 1 [0m
[34mENDING TASK 0, loop 1 [0m
[34mTESTING TASK 0, loop 1 [0m
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│      test_loss_epoch      │    0.6302027106285095     │
│       test_step_acc       │     0.894599974155426     │
└───────────────────────────┴───────────────────────────┘
Iteration: ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 500/500 0:00:10 • 0:00:00 47.08it/s  
                                                                                         
                                                                                         
Testing    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46   0:00:00 • 0:00:00 80.51it/s  
[34mINFO: Generated current run name: d23-04-2024_h18-23-49_lxb5cypv [0m
[31mWARNING: At loop 2 selected last epoch per task "0" because list index out of range. [0m
[31mWARNING: At loop 2 selected last epoch per task "0" because list index out of range. [0m

End of training.
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 10 dimensions.
INFO: Plot model_save/test/ClModel/VGG/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h18-23-49_lxb5cypv/plots/std-mean_idx10
INFO: Plot model_save/test/ClModel/VGG/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h18-23-49_lxb5cypv/plots/distance_class_idx10
INFO: Plot model_save/test/ClModel/VGG/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h18-23-49_lxb5cypv/plots/mean_distance_idx10
INFO: Plot model_save/test/ClModel/VGG/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h18-23-49_lxb5cypv/plots/mean_dist_matrix_idx10
wandb: - 1.912 MB of 1.912 MB uploadedwandb: \ 1.912 MB of 1.912 MB uploadedwandb: | 1.912 MB of 1.912 MB uploadedwandb: / 1.924 MB of 1.954 MB uploaded (0.003 MB deduped)wandb: - 1.924 MB of 1.954 MB uploaded (0.003 MB deduped)wandb: \ 1.954 MB of 1.954 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb: dream_loss/run_0/multi_target_0 ▆█▆▆▅▄▄▃▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_1 ▆█▆▆▅▄▄▃▃▃▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_2 ▆█▆▆▅▅▄▄▃▃▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁
wandb: dream_loss/run_0/multi_target_3 ▅█▆▆▅▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_4 ▆█▇▇▆▆▅▄▄▃▃▃▃▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_5 ▆█▆▆▅▄▃▃▃▃▂▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_6 ▆█▇▆▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_7 ▆█▇▇▆▆▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁
wandb: dream_loss/run_0/multi_target_8 ▆█▆▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_9 ▆█▇▆▆▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                           epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          stats/collect_accuracy █▂▆▃▄▄▅▄▃▃▂▁
wandb:              stats/collect_loss ▃▄▁▆▅▃▅▄█▆▆▇
wandb:                 test_loss_epoch ▁▁
wandb:                  test_loss_step ▄▂▆▅▇█▆▆▇▆▅▅▁▅▇█▅▇▄▅▄▇▄▅█▃▆▅▄▆▅▆▁▇▆█▇▃▄▅
wandb:                   test_step_acc ▁▁
wandb:  train_loss/classification_loss █▄▃▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_loss/total █▄▃▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  train_step_acc ▁▃▅▆▇▇▇█████████████████████████████████
wandb:             trainer/global_step ▁▂▂▃▄▄▅▆▆▇▇▁███████████████████████████▁
wandb:              val_last_step_loss ▇▆▂▁█▂▂▂▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  valid_step_acc ▁▁▅▇▃▆▆▇▇█▇████▇████████████████████████
wandb: 
wandb: Run summary:
wandb: dream_loss/run_0/multi_target_0 0.29523
wandb: dream_loss/run_0/multi_target_1 0.16593
wandb: dream_loss/run_0/multi_target_2 0.47485
wandb: dream_loss/run_0/multi_target_3 0.70697
wandb: dream_loss/run_0/multi_target_4 0.21635
wandb: dream_loss/run_0/multi_target_5 0.36005
wandb: dream_loss/run_0/multi_target_6 0.58094
wandb: dream_loss/run_0/multi_target_7 0.23277
wandb: dream_loss/run_0/multi_target_8 0.23125
wandb: dream_loss/run_0/multi_target_9 0.35756
wandb:                           epoch 0
wandb:          stats/collect_accuracy 0.8822
wandb:              stats/collect_loss 0.86564
wandb:                 test_loss_epoch 0.6302
wandb:                  test_loss_step 0.56017
wandb:                   test_step_acc 0.8946
wandb:  train_loss/classification_loss 0.00261
wandb:                train_loss/total 0.00261
wandb:                  train_step_acc 0.99982
wandb:             trainer/global_step 2420
wandb:              val_last_step_loss 0.6302
wandb:                  valid_step_acc 0.8946
wandb: 
wandb: 🚀 View run exp_search_model_type_vgg_lxb5cypv_crossentropy-multitarget-multitask_dream_tr_ at: https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17/runs/lxb5cypv
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17
wandb: Synced 6 W&B file(s), 15 media file(s), 84 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240423_175132-lxb5cypv/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240423_182432-w6c6jdes
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exp_search_model_type_custom-resnet34_w6c6jdes_crossentropy-multitarget-multitask_dream_tr_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17/runs/w6c6jdes
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: exp_search_model_type_vgg; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: exp_search_model_type_custom-resnet34; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c10', datasampler_type='none', num_tasks=1, framework_type='crossentropy-multitarget-multitask', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], test_at=[True], save=Namespace(model=True, enable_checkpoint=False, dreams=True, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=2, schedule=[300, 0], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=[True], scale=10.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=[1], clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=[True], scale=0.001), l2=Namespace(use_at=[False], coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=None, onehot=Namespace(type='diagonal')), num_classes=10, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='custom-resnet34', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=2.5, scale=2, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=0.0, ratio_gamma=1.0, scale_gamma=1.0, ratio_milestones=None, scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=220, multitarget=Namespace(enable=True, random=False), batch_size=220, optim=Namespace(type='adam', kwargs=Namespace(lr=0.05, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[500], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=[False], enable_vis_at=[1], standard_image_size=[32], decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py']"}
[34mWANDBO RUN ID: w6c6jdes [0m
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: target-classic
	TASK SPLIT: SPLIT-CLASSIC-FILLLAST
	DREAM OBJECTIVE: OBJECTIVE-MULTITARGET-CROSSENTROPY
	MODEL TYPE: custom-resnet34
	OVERLAY TYPE: CL-MODEL [0m
[32mINFO: Using loss DUMMY_LOSS__CrossEntropyLoss [0m
[32mMODEL TYPE: CLModel_CustomResNet34 [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mVIS: Enabled multitarget visualization. Each batch will have multiple targets. [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name            ┃ Type               ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc       │ MulticlassAccuracy │      0 │
│ 1 │ train_acc_dream │ MulticlassAccuracy │      0 │
│ 2 │ _valid_accs     │ ModuleDict         │      0 │
│ 3 │ test_acc        │ MulticlassAccuracy │      0 │
│ 4 │ model           │ CustomResNet34     │ 21.3 M │
│ 5 │ _loss_f         │ DummyLoss          │      0 │
└───┴─────────────────┴────────────────────┴────────┘
Trainable params: 21.3 M                                                                                                                  
Non-trainable params: 0                                                                                                                   
Total params: 21.3 M                                                                                                                      
Total estimated model params size (MB): 85                                                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mTESTING TASK 0, loop 0 [0m
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│      test_loss_epoch      │    0.4387929141521454     │
│       test_step_acc       │    0.9388999938964844     │
└───────────────────────────┴───────────────────────────┘
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 274/274 0:00:21 • 0:00:00 12.71it/s  
Testing   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46   0:00:01 • 0:00:00 38.79it/s  
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[34mINFO: hooking model during visualization to - [33mDEEP INVERSION[34m - task: 0, loop 1 [0m
[34mINFO: For layerloss DeepInversionFeatureLoss used with default value: [36m'10.0'[34m  [0m
[34mINFO: hooking model during visualization to - [33mVARIATION IMAGE REGULARIZATION[34m - task: 0, loop 1 [0m
[34mDREAMING DURING TASK: 0, loop 1 [0m
[36mVIS: Visualization for targets: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9} [0m
[34mVIS: No hook to image after forward and backward pass. [0m
[34mVIS: Optimizer set during visualization config: [32mAdam (
Parameter Group 0
    amsgrad: False
    betas: [0.9, 0.999]
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    weight_decay: 0
) [0m
[32mVIS: Image size before (up/down)sample - torch.Size([220, 3, 41, 41]) [0m
[32mVIS: Image size after (up/down)sample - torch.Size([220, 3, 32, 32]) [0m
[36mVIS: ENABLE DREAM TRANSFORMS [0m
[32mVIS: Current in use image size - torch.Size([220, 3, 32, 32]) [0m
[36mVIS: Number of images to visualize (may change in fast-dev-run): 2200; batch size: 220; per target: 220; batches to be generated: 10 [0m
[36mVIS: Using multitarget visualization [0m
[34mTime generating features: 00:09:44 [0m
[34mDREAMING END [0m
[34mSTARTING TASK 0, loop 1 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[31mINFO: SKIPPING ANY TRAINING at loop 1 [0m
[34mENDING TASK 0, loop 1 [0m
[34mTESTING TASK 0, loop 1 [0m
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│      test_loss_epoch      │    0.4387929141521454     │
│       test_step_acc       │    0.9388999938964844     │
└───────────────────────────┴───────────────────────────┘
Iteration: ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 500/500 0:00:58 • 0:00:00 8.60it/s   
                                                                                         
                                                                                         
Testing    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46   0:00:01 • 0:00:00 38.88it/s  
[34mINFO: Generated current run name: d23-04-2024_h20-24-58_w6c6jdes [0m
[31mWARNING: At loop 2 selected last epoch per task "0" because list index out of range. [0m
[31mWARNING: At loop 2 selected last epoch per task "0" because list index out of range. [0m

End of training.
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 10 dimensions.
INFO: Plot model_save/test/ClModel/CustomResNet34/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h20-24-58_w6c6jdes/plots/std-mean_idx10
INFO: Plot model_save/test/ClModel/CustomResNet34/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h20-24-58_w6c6jdes/plots/distance_class_idx10
INFO: Plot model_save/test/ClModel/CustomResNet34/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h20-24-58_w6c6jdes/plots/mean_distance_idx10
INFO: Plot model_save/test/ClModel/CustomResNet34/layerloss/cfg_deep_inversion/regularization/var/model_optim_type-sgd/-deep_inversion/image_reg_var/d23-04-2024_h20-24-58_w6c6jdes/plots/mean_dist_matrix_idx10
wandb: - 1.982 MB of 1.982 MB uploadedwandb: \ 1.982 MB of 1.982 MB uploadedwandb: | 1.982 MB of 1.982 MB uploadedwandb: / 1.995 MB of 2.025 MB uploaded (0.003 MB deduped)wandb: - 1.995 MB of 2.025 MB uploaded (0.003 MB deduped)wandb: \ 2.025 MB of 2.025 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb: dream_loss/run_0/multi_target_0 ▇▇██▇▇▇▇▆▆▅▅▄▅▅▅▅▄▄▃▃▃▃▂▂▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: dream_loss/run_0/multi_target_1 ▂▇▇█▇▇▇▆▆▅▆▆▅▅▄▅▅▄▄▅▄▃▄▃▄▃▃▂▃▂▂▂▃▂▂▂▁▁▂▂
wandb: dream_loss/run_0/multi_target_2 ▄▆▇██▇▆▇▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▁▂▂▁▁▁
wandb: dream_loss/run_0/multi_target_3 ▂▄▆▇██▇▆▆▆▇▆▅▅▅▅▄▄▄▄▄▄▅▄▃▃▃▃▃▂▂▂▂▂▁▂▁▂▂▁
wandb: dream_loss/run_0/multi_target_4 ▂▇▇▇▇█▆█▇▆▆▅▅▅▅▅▄▃▄▃▄▄▃▄▃▂▃▂▃▃▂▂▂▂▂▁▁▁▂▁
wandb: dream_loss/run_0/multi_target_5 ▄▅▇█▆▇▆▅▄▅▄▅▄▃▃▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁
wandb: dream_loss/run_0/multi_target_6 ▄▄▆▇▇█▇▇▅▆▆▄▅▄▄▄▄▄▄▃▄▃▃▃▃▂▃▂▁▁▂▂▂▂▁▂▁▁▂▂
wandb: dream_loss/run_0/multi_target_7 ▆▄▆▆▇███▇▇▆▆▅▆▅▆▄▄▄▃▄▄▄▃▃▃▃▃▂▂▂▂▁▁▂▂▁▂▂▁
wandb: dream_loss/run_0/multi_target_8 ▄▆█▇▇▇▆▇▅▅▆▆▄▅▄▄▄▃▃▃▃▃▃▃▂▂▃▃▃▂▃▃▂▂▂▂▂▁▁▁
wandb: dream_loss/run_0/multi_target_9 ▅██▇█▇▇▅▆▆▅▄▄▄▅▄▄▄▂▃▃▃▃▃▃▃▂▂▂▃▂▂▂▁▂▂▁▁▂▁
wandb:                           epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          stats/collect_accuracy ▆▃█▅▁▂▂▃▁▂▂▁
wandb:              stats/collect_loss ▃▅▁▆▄▃▃▃█▃▅▇
wandb:                 test_loss_epoch ▁▁
wandb:                  test_loss_step ▃▁▅▄▄█▅▆▄▆▂▃▁▄█▆▃▆▅▅▃▇▃▄▅▅▅▆▄▆▂▃▁▅▆▆▆▂▅▆
wandb:                   test_step_acc ▁▁
wandb:  train_loss/classification_loss █▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train_loss/total █▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  train_step_acc ▁▄▆▇▇▇██████████████████████████████████
wandb:             trainer/global_step ▁▂▂▃▄▄▅▆▆▇▇▁███████████████████████████▁
wandb:              val_last_step_loss █▃▅▂▅▃▂▁▁▂▁▁▅▁▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  valid_step_acc ▁▅▅▇▅▆▇▇█▇██▇█▇▆████████████████████████
wandb: 
wandb: Run summary:
wandb: dream_loss/run_0/multi_target_0 10.30157
wandb: dream_loss/run_0/multi_target_1 13.3443
wandb: dream_loss/run_0/multi_target_2 10.95692
wandb: dream_loss/run_0/multi_target_3 14.58444
wandb: dream_loss/run_0/multi_target_4 14.06498
wandb: dream_loss/run_0/multi_target_5 11.01614
wandb: dream_loss/run_0/multi_target_6 11.25589
wandb: dream_loss/run_0/multi_target_7 12.07791
wandb: dream_loss/run_0/multi_target_8 10.81015
wandb: dream_loss/run_0/multi_target_9 11.63484
wandb:                           epoch 0
wandb:          stats/collect_accuracy 0.93674
wandb:              stats/collect_loss 0.68082
wandb:                 test_loss_epoch 0.43879
wandb:                  test_loss_step 0.53212
wandb:                   test_step_acc 0.9389
wandb:  train_loss/classification_loss 4e-05
wandb:                train_loss/total 4e-05
wandb:                  train_step_acc 0.99998
wandb:             trainer/global_step 2420
wandb:              val_last_step_loss 0.43879
wandb:                  valid_step_acc 0.9389
wandb: 
wandb: 🚀 View run exp_search_model_type_custom-resnet34_w6c6jdes_crossentropy-multitarget-multitask_dream_tr_ at: https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17/runs/w6c6jdes
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-23%3D15-47-17
wandb: Synced 6 W&B file(s), 15 media file(s), 84 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240423_182432-w6c6jdes/logs
End of experiment: exp_search_model_type_custom-resnet34; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
