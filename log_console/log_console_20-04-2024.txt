Global seed set to 2024
wandb: Currently logged in as: 01133344 (cccvb). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240420_035140-pdvurpd7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_DLA_pdvurpd7_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39/runs/pdvurpd7
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Experiments to be run:
* 
-d c10 --model.num_classes 10 --loop.schedule 300 --config.framework_type latent-multitarget --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.kwargs.milestones 140 180 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 220 --model.type DLA
* 
-d c10 --model.num_classes 10 --loop.schedule 300 --config.framework_type latent-multitarget --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.kwargs.milestones 140 180 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 220 --model.type VGG
* 
-d c10 --model.num_classes 10 --loop.schedule 300 --config.framework_type latent-multitarget --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.kwargs.milestones 140 180 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 220 --model.type custom-resnet34

Running experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_DLA; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c10', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=10, onehot=Namespace(type='diagonal')), num_classes=10, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='DLA', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: DLA
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_DLA [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ DLA                 │ 32.6 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 32.6 M                                                                                                                               
Non-trainable params: 0                                                                                                                                
Total params: 32.6 M                                                                                                                                   
Total estimated model params size (MB): 130                                                                                                            
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d20-04-2024_h06-11-43_pdvurpd7 [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 274/274 0:00:27 • 0:00:00 10.03it/s loss: -1.07e+05 v_num: rpd7 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.9016000032424927     │
│      test_loss_epoch      │      -93229.5390625       │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46 0:00:04 • 0:00:00 30.96it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 10 dimensions.
INFO: Plot model_save/test/ClLatentChi/DLA/model_optim_type-sgd/d20-04-2024_h06-11-43_pdvurpd7/plots/std-mean_idx10
INFO: Plot model_save/test/ClLatentChi/DLA/model_optim_type-sgd/d20-04-2024_h06-11-43_pdvurpd7/plots/distance_class_idx10
INFO: Plot model_save/test/ClLatentChi/DLA/model_optim_type-sgd/d20-04-2024_h06-11-43_pdvurpd7/plots/mean_distance_idx10
INFO: Plot model_save/test/ClLatentChi/DLA/model_optim_type-sgd/d20-04-2024_h06-11-43_pdvurpd7/plots/mean_dist_matrix_idx10
wandb: - 1.667 MB of 1.667 MB uploadedwandb: \ 1.667 MB of 1.667 MB uploadedwandb: | 1.667 MB of 1.667 MB uploadedwandb: / 1.694 MB of 1.741 MB uploadedwandb: - 1.694 MB of 1.741 MB uploadedwandb: \ 1.741 MB of 1.741 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▇▇▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▁▁▁▃▂█▅▃▄▃▂▂▁▁▂▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄███████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃███████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy ▅▂█▆▅▄▄▄▂▂▁▁
wandb:     stats/collect_loss ▄▅▁▆▆▆▅▅█▆█▆
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▄▅▁▆▅▅▄▇▅▇▆▃▃▄▇▆▆▂▆▆▃▂▅▅▄▃▇█▆▃▇▇▆▇▃▅▄▅▂▃
wandb:      train_loss/island ████████████▇▇▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ████████████▇▇▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▁▂▃▅▅▃▄▁▂▄▂▅▆▅▆▇▇▇█████████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███▁▁
wandb:     val_last_step_loss ████████████▇▇▅▄▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▁▂▃▅▄▃▅▁▁▃▂▄▄▄▅▅▇▇█████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -108895.07812
wandb:          positive_loss 1239.20642
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.89508
wandb:     stats/collect_loss -91650.35156
wandb:               test_acc 0.9016
wandb:        test_loss_epoch -93229.53906
wandb:         test_loss_step -97622.3125
wandb:      train_loss/island -106955.90625
wandb:       train_loss/total -106955.90625
wandb:         train_step_acc 0.9894
wandb:    trainer/global_step 2420
wandb:     val_last_step_loss -93229.53906
wandb:              valid_acc 0.9016
wandb: 
wandb: 🚀 View run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_DLA_pdvurpd7_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39/runs/pdvurpd7
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39
wandb: Synced 6 W&B file(s), 17 media file(s), 16 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240420_035140-pdvurpd7/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240420_061338-4yfbfqv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_VGG_4yfbfqv2_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39/runs/4yfbfqv2
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_DLA; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_VGG; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c10', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=10, onehot=Namespace(type='diagonal')), num_classes=10, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                                                                
Non-trainable params: 0                                                                                                                                
Total params: 9.2 M                                                                                                                                    
Total estimated model params size (MB): 36                                                                                                             
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d20-04-2024_h07-06-27_4yfbfqv2 [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 274/274 0:00:10 • 0:00:00 27.25it/s loss: -1.1e+05 v_num: fqv2 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.8999000191688538     │
│      test_loss_epoch      │       -92784.640625       │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46 0:00:03 • 0:00:00 72.98it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 10 dimensions.
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d20-04-2024_h07-06-27_4yfbfqv2/plots/std-mean_idx10
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d20-04-2024_h07-06-27_4yfbfqv2/plots/distance_class_idx10
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d20-04-2024_h07-06-27_4yfbfqv2/plots/mean_distance_idx10
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d20-04-2024_h07-06-27_4yfbfqv2/plots/mean_dist_matrix_idx10
wandb: - 1.350 MB of 1.474 MB uploadedwandb: \ 1.350 MB of 1.474 MB uploadedwandb: | 1.350 MB of 1.474 MB uploadedwandb: / 1.474 MB of 1.474 MB uploadedwandb: - 1.474 MB of 1.474 MB uploadedwandb: \ 1.474 MB of 1.474 MB uploadedwandb: | 1.501 MB of 1.548 MB uploaded (0.004 MB deduped)wandb: / 1.501 MB of 1.548 MB uploaded (0.004 MB deduped)wandb: - 1.548 MB of 1.548 MB uploaded (0.004 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▁▁▁▃▂█▇▆▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄███████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃███████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy ▅▅█▆▄▃▃▃▂▂▁▁
wandb:     stats/collect_loss ▃▄▁▇▇▅▂▄█▇▇▇
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▃▄▁▆▆▅▂█▇▇▇▃▄▄█▂▆▁▆▅▅▄▇▅▂▂▃█▆▆▄█▄▇▄▃▅▇▃▄
wandb:      train_loss/island ███████████▇▇▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▇▇▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▂▄▅▆▆▆▇▆▇▇▇▇▇▇▇████████████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███▁▁
wandb:     val_last_step_loss ███████████▇▆▆▂▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▂▄▅▅▆▆▆▃▆▇▅▇▇▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -110488.49219
wandb:          positive_loss 917.12817
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.9
wandb:     stats/collect_loss -89324.55469
wandb:               test_acc 0.8999
wandb:        test_loss_epoch -92784.64062
wandb:         test_loss_step -90898.5625
wandb:      train_loss/island -107584.89062
wandb:       train_loss/total -107584.89062
wandb:         train_step_acc 0.99596
wandb:    trainer/global_step 2420
wandb:     val_last_step_loss -92784.64062
wandb:              valid_acc 0.8999
wandb: 
wandb: 🚀 View run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_VGG_4yfbfqv2_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39/runs/4yfbfqv2
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39
wandb: Synced 6 W&B file(s), 17 media file(s), 16 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240420_061338-4yfbfqv2/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240420_070731-97f88s3l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_custom-resnet34_97f88s3l_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39/runs/97f88s3l
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_VGG; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_custom-resnet34; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c10', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=10, onehot=Namespace(type='diagonal')), num_classes=10, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='custom-resnet34', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: custom-resnet34
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_CustomResNet34 [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ CustomResNet34      │ 21.3 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 21.3 M                                                                                                                               
Non-trainable params: 0                                                                                                                                
Total params: 21.3 M                                                                                                                                   
Total estimated model params size (MB): 85                                                                                                             
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d20-04-2024_h09-25-35_97f88s3l [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 274/274 0:00:27 • 0:00:00 10.10it/s loss: -1.1e+05 v_num: 8s3l 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.9351999759674072     │
│      test_loss_epoch      │      -98842.7890625       │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46 0:00:04 • 0:00:00 31.18it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 10 dimensions.
INFO: Plot model_save/test/ClLatentChi/CustomResNet34/model_optim_type-sgd/d20-04-2024_h09-25-35_97f88s3l/plots/std-mean_idx10
INFO: Plot model_save/test/ClLatentChi/CustomResNet34/model_optim_type-sgd/d20-04-2024_h09-25-35_97f88s3l/plots/distance_class_idx10
INFO: Plot model_save/test/ClLatentChi/CustomResNet34/model_optim_type-sgd/d20-04-2024_h09-25-35_97f88s3l/plots/mean_distance_idx10
INFO: Plot model_save/test/ClLatentChi/CustomResNet34/model_optim_type-sgd/d20-04-2024_h09-25-35_97f88s3l/plots/mean_dist_matrix_idx10
wandb: - 1.290 MB of 1.290 MB uploadedwandb: \ 1.290 MB of 1.290 MB uploadedwandb: | 1.290 MB of 1.290 MB uploadedwandb: / 1.317 MB of 1.364 MB uploaded (0.004 MB deduped)wandb: - 1.317 MB of 1.364 MB uploaded (0.004 MB deduped)wandb: \ 1.364 MB of 1.364 MB uploaded (0.004 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▇▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▂▂▁▄▃█▆█▄▄▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄███████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃███████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy ▅▆█▅▄▄▄▄▂▂▂▁
wandb:     stats/collect_loss ▃▂▁▅▄▄▄▅█▄▆▅
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▃▂▁▅▄▄▄█▄▆▅▁▃▅▆▄▅▁▆▅▅▄▇▅▄▂▃▅▆▃█▆▁▃▂▃▃▆▂▄
wandb:      train_loss/island ███████████▇▇▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▇▇▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▂▂▃▅▆▅▆▅▇▇▅▇▇▇█████████████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███▁▁
wandb:     val_last_step_loss ████████████▇▇▂▂▂█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▂▂▃▄▅▃▆▅▇▆▄▆▆▇▇▇▄██████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -110520.04688
wandb:          positive_loss 50.18892
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.9375
wandb:     stats/collect_loss -97130.20312
wandb:               test_acc 0.9352
wandb:        test_loss_epoch -98842.78906
wandb:         test_loss_step -98911.53906
wandb:      train_loss/island -110501.08594
wandb:       train_loss/total -110501.08594
wandb:         train_step_acc 0.99834
wandb:    trainer/global_step 2420
wandb:     val_last_step_loss -98842.78906
wandb:              valid_acc 0.9352
wandb: 
wandb: 🚀 View run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_custom-resnet34_97f88s3l_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39/runs/97f88s3l
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-20%3D03-51-39
wandb: Synced 6 W&B file(s), 17 media file(s), 16 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240420_070731-97f88s3l/logs
End of experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_custom-resnet34; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
