Experiments to be run:
* 
-d c10 --model.num_classes 10 --loop.schedule 200 --config.framework_type crossentropy-default --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 100 150 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --config.seed 2024 
* 
-d c100 --model.num_classes 100 --loop.schedule 200 --config.framework_type crossentropy-default --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 100 150 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --config.seed 2024 
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 3 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 3 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 220
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 3 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 320
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 3 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 3 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 220
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 3 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 320
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 3 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 3 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 220
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 3 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 320
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 220
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 320
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 220
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 320
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 220
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 320
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 20 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 20 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 220
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 20 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 320
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 20 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 20 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 220
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 20 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 320
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 20 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 20 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 220
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 20 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 320
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 30 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 30 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 220
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 30 --model.loss.chi.ratio 10 --model.loss.chi.scale 80 --datamodule.batch_size 320
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 30 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 30 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 220
Global seed set to 2024
wandb: Currently logged in as: 01133344 (cccvb). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240416_171530-1olzd0gv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_1olzd0gv_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/1olzd0gv
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 30 --model.loss.chi.ratio 10 --model.loss.chi.scale 120 --datamodule.batch_size 320
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 30 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 120
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 30 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 220
* 
-d c100 --model.num_classes 100 --loop.schedule 300 --config.framework_type latent-multitarget --model.type VGG --loop.num_loops 1 --loop.train_at 0 --model.optim.type sgd --model.optim.kwargs.lr 0.1 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --model.sched.kwargs.milestones 140 180 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 30 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 320

Running experiment: crossentropy_default_c10_sgd; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 1).
Running experiment: crossentropy_default_c100_sgd; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 2).
Running experiment: chi_sqr_c100_sgd_search_latent_size_3_chi_ratio_10_chi_scale_80_batch_size_120; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 3).
Running experiment: chi_sqr_c100_sgd_search_latent_size_3_chi_ratio_10_chi_scale_80_batch_size_220; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 4).
Running experiment: chi_sqr_c100_sgd_search_latent_size_3_chi_ratio_10_chi_scale_80_batch_size_320; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 5).
Running experiment: chi_sqr_c100_sgd_search_latent_size_3_chi_ratio_10_chi_scale_120_batch_size_120; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 6).
Running experiment: chi_sqr_c100_sgd_search_latent_size_3_chi_ratio_10_chi_scale_120_batch_size_220; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 7).
Running experiment: chi_sqr_c100_sgd_search_latent_size_3_chi_ratio_10_chi_scale_120_batch_size_320; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 8).
Running experiment: chi_sqr_c100_sgd_search_latent_size_3_chi_ratio_10_chi_scale_160_batch_size_120; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 9).
Running experiment: chi_sqr_c100_sgd_search_latent_size_3_chi_ratio_10_chi_scale_160_batch_size_220; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 10).
Running experiment: chi_sqr_c100_sgd_search_latent_size_3_chi_ratio_10_chi_scale_160_batch_size_320; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 11).
Running experiment: chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_80_batch_size_120; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 12).
Running experiment: chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_80_batch_size_220; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 13).
Running experiment: chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_80_batch_size_320; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 14).
Running experiment: chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_120_batch_size_120; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 15).
Running experiment: chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_120_batch_size_220; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 16).
Running experiment: chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_120_batch_size_320; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 17).
Running experiment: chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_120; repeat 1/1
Experiment skipped because of 'start_at' argument (19 > 18).
Running experiment: chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=10, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d16-04-2024_h18-50-21_1olzd0gv [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 274/274 0:00:19 • 0:00:00 13.92it/s loss: -9.75e+04 v_num: d0gv 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.5881999731063843     │
│      test_loss_epoch      │      -73233.4140625       │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46 0:00:48 • 0:00:00 42.44it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 10 dimensions.
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h18-50-21_1olzd0gv/plots/std-mean_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h18-50-21_1olzd0gv/plots/distance_class_idx15
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h18-50-21_1olzd0gv/plots/distance_class_idx31
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h18-50-21_1olzd0gv/plots/distance_class_idx47
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h18-50-21_1olzd0gv/plots/distance_class_idx63
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h18-50-21_1olzd0gv/plots/distance_class_idx79
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h18-50-21_1olzd0gv/plots/distance_class_idx95
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h18-50-21_1olzd0gv/plots/distance_class_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h18-50-21_1olzd0gv/plots/mean_distance_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h18-50-21_1olzd0gv/plots/mean_dist_matrix_idx100
wandb: - 4.026 MB of 6.163 MB uploadedwandb: \ 5.115 MB of 6.163 MB uploadedwandb: | 5.115 MB of 6.163 MB uploadedwandb: / 6.163 MB of 6.163 MB uploadedwandb: - 6.163 MB of 6.163 MB uploadedwandb: \ 6.163 MB of 6.163 MB uploadedwandb: | 6.303 MB of 6.549 MB uploaded (0.002 MB deduped)wandb: / 6.549 MB of 6.549 MB uploaded (0.002 MB deduped)wandb: - 6.549 MB of 6.549 MB uploaded (0.002 MB deduped)wandb: \ 6.549 MB of 6.549 MB uploaded (0.002 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▇▆▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▁▁▁▂▂█▆▅▅▄▄▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄███████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃███████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy ▄█▁▃▄▄▃▃▅▆▆▇
wandb:     stats/collect_loss ▃▄█▂▄▆▅▇▂▃▅▁
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▄▄▇▃▄▆▅▃▄▅▂▇▄▄▄▃▃█▆█▃▃▁▂▇▅▇▅▄▇▄▇▄▂▁▂▇▅▄▇
wandb:      train_loss/island ███████████▇▇▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▇▇▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▁▂▂▂▂▂▃▃▄▄▄▅▅▅▅▆▆▇▇▇▇██████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████▁▁
wandb:     val_last_step_loss ███████████▇▇▇▃▂▂▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▁▁▂▂▃▂▃▂▃▄▄▅▅▅▆▆▆▆█████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -100821.94531
wandb:          positive_loss 5834.35205
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.59508
wandb:     stats/collect_loss -78912.34375
wandb:               test_acc 0.5882
wandb:        test_loss_epoch -73233.41406
wandb:         test_loss_step -65892.60938
wandb:      train_loss/island -95601.64844
wandb:       train_loss/total -95601.64844
wandb:         train_step_acc 0.83338
wandb:    trainer/global_step 2420
wandb:     val_last_step_loss -73233.41406
wandb:              valid_acc 0.5882
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_1olzd0gv_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/1olzd0gv
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 113 media file(s), 106 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240416_171530-1olzd0gv/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240416_185429-rip6vtgo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_320_rip6vtgo_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/rip6vtgo
End of experiment: chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_320; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=10, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=320)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[34mINFO: Generated:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d16-04-2024_h20-14-11_rip6vtgo [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 189/189 0:00:15 • 0:00:00 12.09it/s loss: -9.65e+04 v_num: vtgo 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.5778999924659729     │
│      test_loss_epoch      │       -71811.03125        │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 32/32 0:00:46 • 0:00:00 36.94it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 10 dimensions.
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h20-14-11_rip6vtgo/plots/std-mean_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h20-14-11_rip6vtgo/plots/distance_class_idx15
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h20-14-11_rip6vtgo/plots/distance_class_idx31
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h20-14-11_rip6vtgo/plots/distance_class_idx47
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h20-14-11_rip6vtgo/plots/distance_class_idx63
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h20-14-11_rip6vtgo/plots/distance_class_idx79
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h20-14-11_rip6vtgo/plots/distance_class_idx95
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h20-14-11_rip6vtgo/plots/distance_class_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h20-14-11_rip6vtgo/plots/mean_distance_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d16-04-2024_h20-14-11_rip6vtgo/plots/mean_dist_matrix_idx100
wandb: - 3.998 MB of 6.117 MB uploadedwandb: \ 6.117 MB of 6.117 MB uploadedwandb: | 6.117 MB of 6.117 MB uploadedwandb: / 6.117 MB of 6.117 MB uploadedwandb: - 6.117 MB of 6.117 MB uploadedwandb: \ 6.117 MB of 6.117 MB uploadedwandb: | 6.257 MB of 6.502 MB uploaded (0.005 MB deduped)wandb: / 6.257 MB of 6.502 MB uploaded (0.005 MB deduped)wandb: - 6.502 MB of 6.502 MB uploaded (0.005 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▇▆▆▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▂▁▁▃▂▂█▆▆▄▄▃▃▂▂▃▂▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄▄██████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃▃██████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy ▁▁▅▅▆▅▇█
wandb:     stats/collect_loss ▄█▅▃▄▃█▁
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▃▆▄▃▄▃▆▁▄▄▄▂▃▆▆▃▁▂▃▅▄▅▃▅▆▂▁▂▅▃▄█
wandb:      train_loss/island ███████████▇▇▇▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▇▇▇▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▁▁▂▂▃▃▃▃▃▄▃▄▅▄▅▆▆▆▇▇▇██████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████▁▁
wandb:     val_last_step_loss ████████████▇▇▄▅▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▁▁▂▂▃▂▃▂▃▃▂▃▄▄▄▅▆▇█████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -99773.65625
wandb:          positive_loss 4388.5332
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.57695
wandb:     stats/collect_loss -77478.3125
wandb:               test_acc 0.5779
wandb:        test_loss_epoch -71811.03125
wandb:         test_loss_step -62319.03516
wandb:      train_loss/island -95591.73438
wandb:       train_loss/total -95591.73438
wandb:         train_step_acc 0.83566
wandb:    trainer/global_step 2240
wandb:     val_last_step_loss -71811.03125
wandb:              valid_acc 0.5779
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_320_rip6vtgo_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/rip6vtgo
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 113 media file(s), 106 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240416_185429-rip6vtgo/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240416_201825-kxohltra
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_120_kxohltra_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/kxohltra
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_320; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_120; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=20, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=80.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=120)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
Epoch 100 ╸                                 10/501 0:00:00 • 0:00:27 18.43it/s loss: 4.38e+19 v_num: ltra 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.015 MB uploadedwandb: | 0.015 MB of 0.015 MB uploadedwandb: / 0.022 MB of 0.045 MB uploaded (0.005 MB deduped)wandb: - 0.038 MB of 0.045 MB uploaded (0.005 MB deduped)wandb: \ 0.038 MB of 0.045 MB uploaded (0.005 MB deduped)wandb: | 0.045 MB of 0.045 MB uploaded (0.005 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 10.2%             
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██
wandb:       negative_loss ████████████████████████▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▃▂▃▂▂▂▂▂▇▇█▆▆▇▆▆
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████████▇▇▆▆▇▆▆▆▁▂▁▁▁▂▁▁
wandb:    train_loss/total ████████████████████████▇▇▆▆▇▆▆▆▁▂▁▁▁▂▁▁
wandb:      train_step_acc ▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▃▄▄▅▅▅▅▆▄▅▅▆▆▇▇▇▅▆▇▇▇▇██
wandb: trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████████▇▇▆▆▆▆▆▆▃▁▁▁▁▁▁▁
wandb:           valid_acc ▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▃▄▄▅▅▅▆▅▃▄▅▆▅▇▆▇▄▇▇▆▇▇▇█
wandb: 
wandb: Run summary:
wandb:               epoch 99
wandb:       negative_loss -99541.6875
wandb:       positive_loss 13073.72266
wandb:               ratio 80.0
wandb:         rho_sigma_2 6400.0
wandb:               scale 80.0
wandb:   train_loss/island -91371.39844
wandb:    train_loss/total -91371.39844
wandb:      train_step_acc 0.47664
wandb: trainer/global_step 41699
wandb:  val_last_step_loss -85643.84375
wandb:           valid_acc 0.4157
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_120_kxohltra_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/kxohltra
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240416_201825-kxohltra/logs
Global seed set to 2024
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240416_210110-xko79idj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_220_xko79idj_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/xko79idj
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_120; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_220; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=20, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=80.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
Epoch 100 ━                                  9/274 0:00:01 • 0:00:24 11.42it/s loss: 1.04e+18 v_num: 9idj 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.015 MB uploadedwandb: | 0.015 MB of 0.036 MB uploadedwandb: / 0.015 MB of 0.038 MB uploadedwandb: - 0.015 MB of 0.038 MB uploadedwandb: \ 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:       negative_loss ████████████████████████▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▂▂▂▂▂▂█▇▆▅▇▅▅▆
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████████▇▇▆▆▆▆▆▆▂▂▁▂▁▁▁▁
wandb:    train_loss/total ████████████████████████▇▇▆▆▆▆▆▆▂▂▁▂▁▁▁▁
wandb:      train_step_acc ▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▅▄▄▅▅▆▆▆▆▄▅▆▆▇▇▇█▄▆▆▇▇▇▇█
wandb: trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████████▇▇▆▆▇▆▆▇▃▃▂▃▁▁▃▁
wandb:           valid_acc ▁▁▁▁▂▂▂▂▂▃▄▄▄▄▄▅▂▃▄▃▆▅▆▆▂▄▅▇▅▇▇▆▃▄▅▅█▇▅█
wandb: 
wandb: Run summary:
wandb:               epoch 99
wandb:       negative_loss -100259.03125
wandb:       positive_loss 10196.83887
wandb:               ratio 80.0
wandb:         rho_sigma_2 6400.0
wandb:               scale 80.0
wandb:   train_loss/island -93310.84375
wandb:    train_loss/total -93310.84375
wandb:      train_step_acc 0.51284
wandb: trainer/global_step 22799
wandb:  val_last_step_loss -75768.73438
wandb:           valid_acc 0.3365
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_220_xko79idj_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/xko79idj
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240416_210110-xko79idj/logs
Global seed set to 2024
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240416_213351-c8d06f2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_320_c8d06f2k_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/c8d06f2k
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_220; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_320; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=20, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=80.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=320)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
Epoch 100 ━╸                                 9/189 0:00:01 • 0:00:16 11.95it/s loss: 3.87e+19 v_num: 6f2k 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.038 MB uploadedwandb: | 0.015 MB of 0.038 MB uploadedwandb: / 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:       negative_loss ████████████████████████▆▆▆▆▆▆▆▆▂▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▂▂▂▂▂▂█▆▇▆▆▄▅▅
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████████▇▆▆▆▆▆▆▆▂▂▂▁▁▁▁▁
wandb:    train_loss/total ████████████████████████▇▆▆▆▆▆▆▆▂▂▂▁▁▁▁▁
wandb:      train_step_acc ▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▃▄▄▅▅▅▆▆▄▅▆▆▇▇▇▇▄▅▆▇▇▇██
wandb: trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████████▇▇▇▇▇▆▇▇▄▅▂▃▃▂▃▁
wandb:           valid_acc ▁▁▁▁▂▂▂▃▂▂▃▂▄▃▂▄▂▂▂▄▄▄▄▅▂▃▃▄▃▇▅▅▂▂▆▄▄▆▅█
wandb: 
wandb: Run summary:
wandb:               epoch 99
wandb:       negative_loss -99454.84375
wandb:       positive_loss 9643.04492
wandb:               ratio 80.0
wandb:         rho_sigma_2 6400.0
wandb:               scale 80.0
wandb:   train_loss/island -93224.07031
wandb:    train_loss/total -93224.07031
wandb:      train_step_acc 0.52674
wandb: trainer/global_step 15699
wandb:  val_last_step_loss -78929.92969
wandb:           valid_acc 0.3979
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_320_c8d06f2k_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/c8d06f2k
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240416_213351-c8d06f2k/logs
Global seed set to 2024
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240416_220047-evyozas9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_120_evyozas9_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/evyozas9
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_80_batch_size_320; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_120; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=20, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=120.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=120)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f20f52329e0>
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/usr/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d17-04-2024_h00-07-39_evyozas9 [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 501/501 0:00:25 • 0:00:00 19.98it/s loss: -3.99e+05 v_num: zas9 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.5730999708175659     │
│      test_loss_epoch      │       -358972.28125       │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84/84 0:00:48 • 0:00:00 54.80it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
/home/ubuntu/continual_dreaming/stats/point_plot.py:369: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  fig.savefig(n)
/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/wandb/sdk/data_types/image.py:302: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  util.ensure_matplotlib_figure(data).savefig(buf, format="png")
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 20 dimensions.
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h00-07-39_evyozas9/plots/std-mean_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h00-07-39_evyozas9/plots/distance_class_idx15
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h00-07-39_evyozas9/plots/distance_class_idx31
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h00-07-39_evyozas9/plots/distance_class_idx47
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h00-07-39_evyozas9/plots/distance_class_idx63
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h00-07-39_evyozas9/plots/distance_class_idx79
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h00-07-39_evyozas9/plots/distance_class_idx95
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h00-07-39_evyozas9/plots/distance_class_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h00-07-39_evyozas9/plots/mean_distance_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h00-07-39_evyozas9/plots/mean_dist_matrix_idx100
wandb: - 5.975 MB of 6.246 MB uploadedwandb: \ 5.612 MB of 6.246 MB uploadedwandb: | 5.612 MB of 6.246 MB uploadedwandb: / 5.612 MB of 6.246 MB uploadedwandb: - 5.612 MB of 6.246 MB uploadedwandb: \ 6.386 MB of 6.627 MB uploaded (0.005 MB deduped)wandb: | 6.386 MB of 6.627 MB uploaded (0.005 MB deduped)wandb: / 6.627 MB of 6.627 MB uploaded (0.005 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▆▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▁▁▁▃▃▂█▇▇▇▆▄▄▄▃▃▃▃▄▃▃▃▃▄▃▃▃▃▄▄▃▂
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄▄██████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃▃██████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy ▇█▆▃▁▁▂▂▂▂▂▂▂▂▁▂▃▃▃▃▃
wandb:     stats/collect_loss ▃▄▄██▁▂▅▄▄▂▂▆▇▅▁▂▄▅▄▃
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▃▄▇▂▄▂▆▅▄▄▆▇▇▅▄▂▂▇▃▄▆▄▃▂▇▁▄▄▄▇▃▆▂▂▂▃▅▆▁█
wandb:      train_loss/island ███████████▇▆▆▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▇▆▆▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▁▁▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇█████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████▁▁
wandb:     val_last_step_loss ███████████▆▆▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▁▁▂▂▃▃▃▃▄▅▄▅▆▅▆▆▇▇█████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -416026.90625
wandb:          positive_loss 17307.42383
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 120.0
wandb: stats/collect_accuracy 0.58254
wandb:     stats/collect_loss -363746.25
wandb:               test_acc 0.5731
wandb:        test_loss_epoch -358972.28125
wandb:         test_loss_step -333628.375
wandb:      train_loss/island -402301.125
wandb:       train_loss/total -402301.125
wandb:         train_step_acc 0.72696
wandb:    trainer/global_step 2400
wandb:     val_last_step_loss -358972.28125
wandb:              valid_acc 0.5731
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_120_evyozas9_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/evyozas9
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 113 media file(s), 106 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240416_220047-evyozas9/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_001141-vo4vpi1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_220_vo4vpi1r_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/vo4vpi1r
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_120; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_220; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=20, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=120.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
Epoch 100 ━╸                                15/274 0:00:01 • 0:00:20 13.48it/s loss: 4.75e+22 v_num: pi1r 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.038 MB uploadedwandb: | 0.015 MB of 0.038 MB uploadedwandb: / 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:       negative_loss ████████████████████████▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▂▃▂▂▂▂▆█▅▅▇▅▅▅
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████████▇▇▇▆▇▆▆▆▂▂▂▂▂▂▁▁
wandb:    train_loss/total ████████████████████████▇▇▇▆▇▆▆▆▂▂▂▂▂▂▁▁
wandb:      train_step_acc ▁▁▂▂▂▂▂▂▂▂▃▃▄▄▄▄▃▄▄▅▅▅▅▆▄▅▅▆▆▆▇▇▅▆▆▇▇▇██
wandb: trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████████▇▇▇▇▇▇▇▆▅▂▃▂▂▂▃▁
wandb:           valid_acc ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▁▃▃▄▄▄▄▄▂▃▄▄▄▅▄▆▂▅▄▅▆▅▅█
wandb: 
wandb: Run summary:
wandb:               epoch 99
wandb:       negative_loss -99375.125
wandb:       positive_loss 8257.77539
wandb:               ratio 80.0
wandb:         rho_sigma_2 6400.0
wandb:               scale 120.0
wandb:   train_loss/island -96563.01562
wandb:    train_loss/total -96563.01562
wandb:      train_step_acc 0.51614
wandb: trainer/global_step 22799
wandb:  val_last_step_loss -84095.91406
wandb:           valid_acc 0.4368
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_220_vo4vpi1r_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/vo4vpi1r
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_001141-vo4vpi1r/logs
Global seed set to 2024
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_004351-xqho50b6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_320_xqho50b6_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/xqho50b6
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_220; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_320; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=20, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=120.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=320)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
Epoch 100 ━━                                13/189 0:00:01 • 0:00:16 11.23it/s loss: 6.93e+22 v_num: 50b6 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.038 MB uploadedwandb: | 0.015 MB of 0.038 MB uploadedwandb: / 0.015 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:       negative_loss ████████████████████████▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▂▂▂▂▇█▇▇▆▆▆▅
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████████▇▇▇▆▆▆▆▆▂▂▁▁▁▁▁▁
wandb:    train_loss/total ████████████████████████▇▇▇▆▆▆▆▆▂▂▁▁▁▁▁▁
wandb:      train_step_acc ▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▃▃▄▄▅▅▅▆▃▅▅▆▆▆▇▇▅▆▇▇▇▇██
wandb: trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████████▇▇▆▆▆▆▇▇▆▁▂▁▂▁▂▂
wandb:           valid_acc ▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▂▄▃▄▅▄▄▇▁▄▅▇▆█▅▆▁▆▅▇▅█▆█
wandb: 
wandb: Run summary:
wandb:               epoch 99
wandb:       negative_loss -99330.20312
wandb:       positive_loss 9154.17188
wandb:               ratio 80.0
wandb:         rho_sigma_2 6400.0
wandb:               scale 120.0
wandb:   train_loss/island -91871.90625
wandb:    train_loss/total -91871.90625
wandb:      train_step_acc 0.53312
wandb: trainer/global_step 15699
wandb:  val_last_step_loss -66347.35938
wandb:           valid_acc 0.2988
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_320_xqho50b6_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/xqho50b6
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_004351-xqho50b6/logs
Global seed set to 2024
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_011127-8my0pyi7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_120_8my0pyi7_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/8my0pyi7
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_120_batch_size_320; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_120; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=20, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=120)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d17-04-2024_h03-18-42_8my0pyi7 [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 501/501 0:00:25 • 0:00:00 19.61it/s loss: -3.95e+05 v_num: pyi7 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.5539000034332275     │
│      test_loss_epoch      │       -357942.1875        │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84/84 0:00:47 • 0:00:00 54.13it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
/home/ubuntu/continual_dreaming/stats/point_plot.py:369: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  fig.savefig(n)
/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/wandb/sdk/data_types/image.py:302: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  util.ensure_matplotlib_figure(data).savefig(buf, format="png")
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 20 dimensions.
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h03-18-42_8my0pyi7/plots/std-mean_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h03-18-42_8my0pyi7/plots/distance_class_idx15
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h03-18-42_8my0pyi7/plots/distance_class_idx31
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h03-18-42_8my0pyi7/plots/distance_class_idx47
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h03-18-42_8my0pyi7/plots/distance_class_idx63
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h03-18-42_8my0pyi7/plots/distance_class_idx79
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h03-18-42_8my0pyi7/plots/distance_class_idx95
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h03-18-42_8my0pyi7/plots/distance_class_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h03-18-42_8my0pyi7/plots/mean_distance_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h03-18-42_8my0pyi7/plots/mean_dist_matrix_idx100
wandb: - 2.431 MB of 6.312 MB uploadedwandb: \ 2.431 MB of 6.312 MB uploadedwandb: | 6.312 MB of 6.312 MB uploadedwandb: / 6.312 MB of 6.312 MB uploadedwandb: - 6.312 MB of 6.312 MB uploadedwandb: \ 6.452 MB of 6.693 MB uploaded (0.005 MB deduped)wandb: | 6.693 MB of 6.693 MB uploaded (0.005 MB deduped)wandb: / 6.693 MB of 6.693 MB uploaded (0.005 MB deduped)wandb: - 6.693 MB of 6.693 MB uploaded (0.005 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▆▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▁▁▁▂▂▂█▇▆▇▅▄▅▅▂▄▃▃▄▃▂▃▂▅▃▂▃▃▃▄▃▂
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄▄██████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃▃██████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy ▅█▇▃▁▁▃▂▁▁▂▃▃▂▂▂▃▃▃▃▃
wandb:     stats/collect_loss ▄▂▃▅█▁▃▅▅▅▂▃▅▆▂▂▂▄▄▃▃
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▄▃█▃▅▂▅▂▄▃▃▆▅▅▄▃▃▄▁▄▃▄▃▃▆▃▃▄▅▄▄▆▂▁▂▃▅▅▂█
wandb:      train_loss/island ███████████▇▆▇▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▇▆▇▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇█████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████▁▁
wandb:     val_last_step_loss ███████████▆▆▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▁▁▂▂▃▂▄▃▄▅▄▅▅▅▆▆▇▇█████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -416339.4375
wandb:          positive_loss 17348.42383
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.55437
wandb:     stats/collect_loss -365271.0625
wandb:               test_acc 0.5539
wandb:        test_loss_epoch -357942.1875
wandb:         test_loss_step -323227.21875
wandb:      train_loss/island -390016.59375
wandb:       train_loss/total -390016.59375
wandb:         train_step_acc 0.70164
wandb:    trainer/global_step 2400
wandb:     val_last_step_loss -357942.1875
wandb:              valid_acc 0.5539
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_120_8my0pyi7_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/8my0pyi7
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 113 media file(s), 106 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_011127-8my0pyi7/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_032246-utkt6pba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_220_utkt6pba_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/utkt6pba
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_120; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_220; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=20, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d17-04-2024_h04-57-13_utkt6pba [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 274/274 0:00:18 • 0:00:00 14.66it/s loss: -4.03e+05 v_num: 6pba 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.5799000263214111     │
│      test_loss_epoch      │        -352306.125        │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46 0:00:46 • 0:00:00 41.77it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
/home/ubuntu/continual_dreaming/stats/point_plot.py:369: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  fig.savefig(n)
/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/wandb/sdk/data_types/image.py:302: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  util.ensure_matplotlib_figure(data).savefig(buf, format="png")
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 20 dimensions.
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h04-57-13_utkt6pba/plots/std-mean_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h04-57-13_utkt6pba/plots/distance_class_idx15
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h04-57-13_utkt6pba/plots/distance_class_idx31
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h04-57-13_utkt6pba/plots/distance_class_idx47
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h04-57-13_utkt6pba/plots/distance_class_idx63
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h04-57-13_utkt6pba/plots/distance_class_idx79
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h04-57-13_utkt6pba/plots/distance_class_idx95
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h04-57-13_utkt6pba/plots/distance_class_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h04-57-13_utkt6pba/plots/mean_distance_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h04-57-13_utkt6pba/plots/mean_dist_matrix_idx100
wandb: - 6.134 MB of 6.370 MB uploadedwandb: \ 5.431 MB of 6.370 MB uploadedwandb: | 5.431 MB of 6.370 MB uploadedwandb: / 5.431 MB of 6.370 MB uploadedwandb: - 6.370 MB of 6.370 MB uploadedwandb: \ 6.370 MB of 6.370 MB uploadedwandb: | 6.510 MB of 6.751 MB uploaded (0.005 MB deduped)wandb: / 6.751 MB of 6.751 MB uploaded (0.005 MB deduped)wandb: - 6.751 MB of 6.751 MB uploaded (0.005 MB deduped)wandb: \ 6.751 MB of 6.751 MB uploaded (0.005 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▆▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▁▁▁▃▃█▇▆▅▄▄▄▃▃▃▃▂▃▃▃▂▄▃▂▂▂▃▂▂▃▃▂
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄███████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃███████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy █▅▂▃▂▁▁▁▂▂▂▂
wandb:     stats/collect_loss ▁▅█▄▃▃▃▃▁▄▄▁
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▃▅▇▄▄▄▄▃▄▄▂▇▅▄▅▃▃▇▅█▂▃▁▂▆▄▆▆▄▇▅█▅▃▁▃▅▅▄▇
wandb:      train_loss/island ███████████▇▇▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▇▇▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▁▂▂▂▂▂▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████▁▁
wandb:     val_last_step_loss ███████████▇▇▆▂▂▄▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▁▁▁▂▂▂▃▂▃▅▃▄▅▄▄▃▆▆█████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -416436.28125
wandb:          positive_loss 9187.17383
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.58447
wandb:     stats/collect_loss -362553.125
wandb:               test_acc 0.5799
wandb:        test_loss_epoch -352306.125
wandb:         test_loss_step -340432.59375
wandb:      train_loss/island -405421.1875
wandb:       train_loss/total -405421.1875
wandb:         train_step_acc 0.78892
wandb:    trainer/global_step 2420
wandb:     val_last_step_loss -352306.125
wandb:              valid_acc 0.5799
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_220_utkt6pba_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/utkt6pba
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 113 media file(s), 106 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_032246-utkt6pba/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_050118-22c5zws1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_320_22c5zws1_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/22c5zws1
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_220; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_320; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=20, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=320)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d17-04-2024_h06-20-21_22c5zws1 [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 189/189 0:00:15 • 0:00:00 12.64it/s loss: -3.99e+05 v_num: zws1 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.5605999827384949     │
│      test_loss_epoch      │        -347264.125        │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 32/32 0:00:45 • 0:00:00 34.35it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
/home/ubuntu/continual_dreaming/stats/point_plot.py:369: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  fig.savefig(n)
/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/wandb/sdk/data_types/image.py:302: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  util.ensure_matplotlib_figure(data).savefig(buf, format="png")
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 20 dimensions.
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h06-20-21_22c5zws1/plots/std-mean_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h06-20-21_22c5zws1/plots/distance_class_idx15
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h06-20-21_22c5zws1/plots/distance_class_idx31
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h06-20-21_22c5zws1/plots/distance_class_idx47
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h06-20-21_22c5zws1/plots/distance_class_idx63
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h06-20-21_22c5zws1/plots/distance_class_idx79
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h06-20-21_22c5zws1/plots/distance_class_idx95
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h06-20-21_22c5zws1/plots/distance_class_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h06-20-21_22c5zws1/plots/mean_distance_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h06-20-21_22c5zws1/plots/mean_dist_matrix_idx100
wandb: - 4.227 MB of 6.439 MB uploadedwandb: \ 2.431 MB of 6.439 MB uploadedwandb: | 2.431 MB of 6.439 MB uploadedwandb: / 2.431 MB of 6.439 MB uploadedwandb: - 6.439 MB of 6.439 MB uploadedwandb: \ 6.439 MB of 6.439 MB uploadedwandb: | 6.579 MB of 6.820 MB uploaded (0.005 MB deduped)wandb: / 6.579 MB of 6.820 MB uploaded (0.005 MB deduped)wandb: - 6.579 MB of 6.820 MB uploaded (0.005 MB deduped)wandb: \ 6.820 MB of 6.820 MB uploaded (0.005 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▆▆▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▁▁▁▂▂▂█▄▄▄▄▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄▄██████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃▃██████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy █▁▂▄▂▄▅▅
wandb:     stats/collect_loss ▃█▃▁▆▁▆▂
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▃▆▃▂▅▂▅▂▆▅▅▃▂▃▆▂▂▂▁▄▅▄▃▄▆▁▂▂▅▃▄█
wandb:      train_loss/island ███████████▇▆▆▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▇▆▆▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▁▂▂▂▃▃▄▃▄▅▄▅▅▃▅▅▆▆▇▇▇▇█████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████▁▁
wandb:     val_last_step_loss ▇▇▇▇▇▇▇▇▇▇▇█▆▆▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▁▁▂▂▃▂▃▂▄▅▁▃▅▂▄▄▅▆█████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -411735.0625
wandb:          positive_loss 13107.50977
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.56055
wandb:     stats/collect_loss -353579.09375
wandb:               test_acc 0.5606
wandb:        test_loss_epoch -347264.125
wandb:         test_loss_step -326972.34375
wandb:      train_loss/island -398730.78125
wandb:       train_loss/total -398730.78125
wandb:         train_step_acc 0.76702
wandb:    trainer/global_step 2240
wandb:     val_last_step_loss -347264.125
wandb:              valid_acc 0.5606
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_320_22c5zws1_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/22c5zws1
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 113 media file(s), 106 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_050118-22c5zws1/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_062427-k03bkepd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_120_k03bkepd_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/k03bkepd
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_20_chi_ratio_10_chi_scale_160_batch_size_320; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_120; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=30, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=80.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=120)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d17-04-2024_h08-29-43_k03bkepd [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 501/501 0:00:24 • 0:00:00 20.48it/s loss: 8.49e+08 v_num: kepd 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │   0.009999999776482582    │
│      test_loss_epoch      │        74518848.0         │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84/84 0:00:49 • 0:00:00 55.50it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
/home/ubuntu/continual_dreaming/stats/point_plot.py:369: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  fig.savefig(n)
/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/wandb/sdk/data_types/image.py:302: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  util.ensure_matplotlib_figure(data).savefig(buf, format="png")
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 30 dimensions.
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h08-29-43_k03bkepd/plots/std-mean_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h08-29-43_k03bkepd/plots/distance_class_idx15
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h08-29-43_k03bkepd/plots/distance_class_idx31
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h08-29-43_k03bkepd/plots/distance_class_idx47
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h08-29-43_k03bkepd/plots/distance_class_idx63
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h08-29-43_k03bkepd/plots/distance_class_idx79
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h08-29-43_k03bkepd/plots/distance_class_idx95
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h08-29-43_k03bkepd/plots/distance_class_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h08-29-43_k03bkepd/plots/mean_distance_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h08-29-43_k03bkepd/plots/mean_dist_matrix_idx100
wandb: - 3.786 MB of 3.846 MB uploadedwandb: \ 3.786 MB of 3.846 MB uploadedwandb: | 3.846 MB of 3.846 MB uploadedwandb: / 3.846 MB of 3.846 MB uploadedwandb: - 3.846 MB of 3.846 MB uploadedwandb: \ 3.846 MB of 3.846 MB uploadedwandb: | 3.985 MB of 4.226 MB uploaded (0.005 MB deduped)wandb: / 3.985 MB of 4.226 MB uploaded (0.005 MB deduped)wandb: - 4.226 MB of 4.226 MB uploaded (0.005 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁▁█
wandb:          positive_loss ▁▁▁▁▁▁▁▁▃▂▂█▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄▄██████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃▃██████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy ▁▆█▆▅▅▅▆▆▇▆▇▆▆▆▇▇▇▇▇▇
wandb:     stats/collect_loss ▂▁▁▂▁▂▁▂▂▁▂█▁▂▂▁▁▂▂▂▂
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▃▁▁▁▁█▁▁▃▁▁▁▁▆▁▃▃▃▁▃▁▆▁▁▃▁▃▆▁█▁▁▃▁▃▃▁▆▁▁
wandb:      train_loss/island ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▂▂▃▄▄▅▅▆▆▇▇▆▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████▁▁
wandb:     val_last_step_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▂▁▂▁▂▁▂▁▁▁▂▁▁▂▂▂▁▂▁▁▁▁
wandb:              valid_acc ▂▂▃▃▄▅▅▅▆▆▇▆▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss 1095264512.0
wandb:          positive_loss 161.18095
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 80.0
wandb: stats/collect_accuracy 0.00913
wandb:     stats/collect_loss 759690112.0
wandb:               test_acc 0.01
wandb:        test_loss_epoch 74518848.0
wandb:         test_loss_step 4126393.75
wandb:      train_loss/island 4126393.25
wandb:       train_loss/total 4126393.25
wandb:         train_step_acc 0.00982
wandb:    trainer/global_step 2400
wandb:     val_last_step_loss 74518848.0
wandb:              valid_acc 0.01
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_120_k03bkepd_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/k03bkepd
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 113 media file(s), 106 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_062427-k03bkepd/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_083400-triy772x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_220_triy772x_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/triy772x
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_120; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_220; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=30, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=80.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
Epoch 80  ━━━╸                              33/274 0:00:02 • 0:00:20 12.17it/s loss: 1.21e+22 v_num: 772x 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.015 MB uploadedwandb: | 0.015 MB of 0.037 MB uploadedwandb: / 0.015 MB of 0.037 MB uploadedwandb: - 0.037 MB of 0.037 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:       negative_loss ████████████████████▇▇▇▇▇▇▇▇▇▇▁▁▁▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▂▂▂▂▂▂▂▂██▆▆▆▅▆▅▅▆
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃██████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂██████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████▇▇▇▇▇▇▇▆▆▆▂▁▁▁▁▁▁▁▁▁
wandb:    train_loss/total ████████████████████▇▇▇▇▇▇▇▆▆▆▂▁▁▁▁▁▁▁▁▁
wandb:      train_step_acc ▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▄▄▅▅▆▆▆▆▇▇▅▆▆▇▇▇▇███
wandb: trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████▇▇▇▆▆▇▇▆▆▇▄▃▂▁▃▁▂▁▁▁
wandb:           valid_acc ▁▂▁▁▁▂▂▁▃▃▃▃▄▄▃▃▄▅▃▄▃▃▄▆▆▆▆▇▇▆▂▃▅▇▃▇▅██▇
wandb: 
wandb: Run summary:
wandb:               epoch 80
wandb:       negative_loss -50274.79688
wandb:       positive_loss 9442.45898
wandb:               ratio 80.0
wandb:         rho_sigma_2 6400.0
wandb:               scale 80.0
wandb:   train_loss/island -36694.78125
wandb:    train_loss/total -36694.78125
wandb:      train_step_acc 0.47066
wandb: trainer/global_step 18249
wandb:  val_last_step_loss -38077.28125
wandb:           valid_acc 0.2842
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_220_triy772x_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/triy772x
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_083400-triy772x/logs
Global seed set to 2024
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_085952-0vgxjcam
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_320_0vgxjcam_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/0vgxjcam
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_220; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_320; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=30, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=80.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=320)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
Epoch 80  ━━━━╸                             26/189 0:00:02 • 0:00:16 10.70it/s loss: 2.04e+21 v_num: jcam 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.037 MB uploadedwandb: | 0.015 MB of 0.037 MB uploadedwandb: / 0.037 MB of 0.037 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:       negative_loss ████████████████████▇▇▇▇▇▇▇▇▇▇▁▁▁▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▃▂▂▂▂▂▂▂██▇▆▆▅▆▅▆▅
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃██████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂██████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████▇▇▇▇▇▇▇▇▇▆▂▂▁▁▁▁▁▁▁▁
wandb:    train_loss/total ████████████████████▇▇▇▇▇▇▇▇▇▆▂▂▁▁▁▁▁▁▁▁
wandb:      train_step_acc ▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▃▄▄▅▅▅▅▆▆▆▄▅▆▆▇▇▇▇██
wandb: trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████▇▇▇▇▇▇▇▇▇▇▄▃▃▅▂▃▁▄▁▁
wandb:           valid_acc ▁▁▁▁▂▁▂▂▂▃▃▃▃▄▂▃▄▄▅▄▂▄▂▅▅▃▅▃▆▅▁▃▃▂▅▄█▃█▇
wandb: 
wandb: Run summary:
wandb:               epoch 79
wandb:       negative_loss -47514.98828
wandb:       positive_loss 3769.29639
wandb:               ratio 40.0
wandb:         rho_sigma_2 1600.0
wandb:               scale 80.0
wandb:   train_loss/island -44767.64453
wandb:    train_loss/total -44767.64453
wandb:      train_step_acc 0.4776
wandb: trainer/global_step 12559
wandb:  val_last_step_loss -37768.07812
wandb:           valid_acc 0.3077
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_320_0vgxjcam_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/0vgxjcam
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_085952-0vgxjcam/logs
Global seed set to 2024
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_092259-p6559ypo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_120_p6559ypo_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/p6559ypo
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_80_batch_size_320; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_120; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=30, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=120.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=120)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
Epoch 100 ╸                                 12/501 0:00:00 • 0:00:24 20.61it/s loss: 1.24e+28 v_num: 9ypo 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.015 MB uploadedwandb: | 0.015 MB of 0.038 MB uploadedwandb: / 0.015 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██
wandb:       negative_loss ████████████████████████▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▂▂▂▂▂▂▆█▆▅▆▆▆▆
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████████▆▆▆▆▆▆▆▆▂▁▁▁▁▁▁▁
wandb:    train_loss/total ████████████████████████▆▆▆▆▆▆▆▆▂▁▁▁▁▁▁▁
wandb:      train_step_acc ▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▃▄▄▅▅▅▅▆▄▅▅▆▆▆▇▇▅▆▇▇▇▇██
wandb: trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████████▇▆▆▆▆▆▆▆▂▁▁▁▁▁▁▁
wandb:           valid_acc ▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▃▃▄▅▅▅▆▅▄▅▅▆▇▆▇▇▄▆▇▆████
wandb: 
wandb: Run summary:
wandb:               epoch 99
wandb:       negative_loss -195966.64062
wandb:       positive_loss 13833.76855
wandb:               ratio 80.0
wandb:         rho_sigma_2 6400.0
wandb:               scale 120.0
wandb:   train_loss/island -171484.92188
wandb:    train_loss/total -171484.92188
wandb:      train_step_acc 0.46464
wandb: trainer/global_step 41699
wandb:  val_last_step_loss -170077.60938
wandb:           valid_acc 0.406
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_120_p6559ypo_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/p6559ypo
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_092259-p6559ypo/logs
Global seed set to 2024
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_100537-awocu41k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_220_awocu41k_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/awocu41k
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_120; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_220; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=30, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=120.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
Epoch 100 ━╸                                14/274 0:00:01 • 0:00:18 14.48it/s loss: 2.49e+18 v_num: u41k 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.015 MB uploadedwandb: | 0.015 MB of 0.038 MB uploadedwandb: / 0.015 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:       negative_loss ████████████████████████▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂█▆▅▅▇▅▅▄
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████████▇▆▆▆▆▆▆▆▂▁▁▁▁▁▁▁
wandb:    train_loss/total ████████████████████████▇▆▆▆▆▆▆▆▂▁▁▁▁▁▁▁
wandb:      train_step_acc ▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▃▄▄▄▅▅▅▆▄▅▆▆▆▆▇▇▅▆▇▇▇███
wandb: trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████████▇▇▆█▆▇▆▇▄▃▂▂▁▂▃▁
wandb:           valid_acc ▁▁▁▁▂▂▂▂▂▂▂▂▃▄▃▃▂▃▃▄▄▅▅▄▂▃▅▂▅▄▆▅▂▃▄▅▇▆▄█
wandb: 
wandb: Run summary:
wandb:               epoch 99
wandb:       negative_loss -195937.75
wandb:       positive_loss 12110.08984
wandb:               ratio 80.0
wandb:         rho_sigma_2 6400.0
wandb:               scale 120.0
wandb:   train_loss/island -169777.0625
wandb:    train_loss/total -169777.0625
wandb:      train_step_acc 0.50316
wandb: trainer/global_step 22799
wandb:  val_last_step_loss -168701.29688
wandb:           valid_acc 0.4008
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_220_awocu41k_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/awocu41k
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_100537-awocu41k/logs
Global seed set to 2024
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_103747-723j18ey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_320_723j18ey_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/723j18ey
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_220; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_320; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=30, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=120.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=320)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
Epoch 100 ━╸                                11/189 0:00:01 • 0:00:16 11.82it/s loss: 1.56e+19 v_num: 18ey 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.036 MB uploadedwandb: | 0.038 MB of 0.038 MB uploadedwandb: / 0.038 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:       negative_loss ████████████████████████▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▃▂▂▃▃▂██▇▇▆▆▆▅
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████████▇▆▆▆▆▆▆▆▂▁▁▁▁▁▁▁
wandb:    train_loss/total ████████████████████████▇▆▆▆▆▆▆▆▂▁▁▁▁▁▁▁
wandb:      train_step_acc ▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▃▄▄▄▅▅▅▆▃▅▅▆▆▆▇▇▅▆▇▇▇▇██
wandb: trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████████▇▆▇▆▇▆▆▆▂▃▁▃▂▁▁▁
wandb:           valid_acc ▁▁▂▂▂▂▂▂▂▃▃▃▃▄▅▅▂▃▄▅▃▃▆▆▂▅▄▆▅▇█▇▅▃▇▄▅▆▇█
wandb: 
wandb: Run summary:
wandb:               epoch 99
wandb:       negative_loss -192347.95312
wandb:       positive_loss 13892.14746
wandb:               ratio 80.0
wandb:         rho_sigma_2 6400.0
wandb:               scale 120.0
wandb:   train_loss/island -167273.8125
wandb:    train_loss/total -167273.8125
wandb:      train_step_acc 0.48878
wandb: trainer/global_step 15699
wandb:  val_last_step_loss -145758.32812
wandb:           valid_acc 0.2779
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_320_723j18ey_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/723j18ey
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_103747-723j18ey/logs
Global seed set to 2024
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_110459-0m549hek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_120_0m549hek_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/0m549hek
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_120_batch_size_320; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_120; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=30, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=120)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mChanged learning rate from: '[0.1]' to: '[0.010000000000000002]' for optimizer index: 0 at epoch: 139 [0m
[34mChanged learning rate from: '[0.010000000000000002]' to: '[0.0010000000000000002]' for optimizer index: 0 at epoch: 179 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.0010000000000000002] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d17-04-2024_h13-10-34_0m549hek [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 501/501 0:00:24 • 0:00:00 20.91it/s loss: -7.72e+05 v_num: 9hek 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.5511000156402588     │
│      test_loss_epoch      │        -713594.625        │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84/84 0:00:49 • 0:00:00 56.04it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
/home/ubuntu/continual_dreaming/stats/point_plot.py:369: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  fig.savefig(n)
/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/wandb/sdk/data_types/image.py:302: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  util.ensure_matplotlib_figure(data).savefig(buf, format="png")
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 30 dimensions.
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h13-10-34_0m549hek/plots/std-mean_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h13-10-34_0m549hek/plots/distance_class_idx15
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h13-10-34_0m549hek/plots/distance_class_idx31
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h13-10-34_0m549hek/plots/distance_class_idx47
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h13-10-34_0m549hek/plots/distance_class_idx63
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h13-10-34_0m549hek/plots/distance_class_idx79
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h13-10-34_0m549hek/plots/distance_class_idx95
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h13-10-34_0m549hek/plots/distance_class_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h13-10-34_0m549hek/plots/mean_distance_idx100
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-sgd/d17-04-2024_h13-10-34_0m549hek/plots/mean_dist_matrix_idx100
wandb: - 4.406 MB of 6.648 MB uploadedwandb: \ 4.406 MB of 6.648 MB uploadedwandb: | 6.648 MB of 6.648 MB uploadedwandb: / 6.648 MB of 6.648 MB uploadedwandb: - 6.648 MB of 6.648 MB uploadedwandb: \ 6.648 MB of 6.648 MB uploadedwandb: | 6.648 MB of 6.648 MB uploadedwandb: / 6.787 MB of 7.028 MB uploaded (0.005 MB deduped)wandb: - 7.028 MB of 7.028 MB uploaded (0.005 MB deduped)wandb: \ 7.028 MB of 7.028 MB uploaded (0.005 MB deduped)wandb: | 7.028 MB of 7.028 MB uploaded (0.005 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▆▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▁▁▁▃▃▂▇█▇▆▆▅▃▃▃▃▃▃▃▄▃▃▂▃▃▄▄▃▃▃▃▄
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄▄██████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃▃██████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy █▇▅▂▂▃▃▃▃▂▂▂▂▂▁▁▂▃▃▃▃
wandb:     stats/collect_loss ▄▃▅▇█▁▃▅▃▄▄▅▆▅▆▁▁▄▆▃▁
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▃▄▆▃▃▃▄▄▃▃▃▇▆▄▅▂▃▆▂▃▄▂▂▂▄▃▃▆▄▇▄▆▁▂▂▃▄▄▂█
wandb:      train_loss/island ███████████▇▇▆▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▇▇▆▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇█████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████▁▁
wandb:     val_last_step_loss ███████████▆▆▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▁▁▁▂▃▃▃▃▄▄▄▅▅▄▅▆▇▇█████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -800281.4375
wandb:          positive_loss 43053.55078
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.56071
wandb:     stats/collect_loss -735968.875
wandb:               test_acc 0.5511
wandb:        test_loss_epoch -713594.625
wandb:         test_loss_step -657557.75
wandb:      train_loss/island -770127.875
wandb:       train_loss/total -770127.875
wandb:         train_step_acc 0.70798
wandb:    trainer/global_step 2400
wandb:     val_last_step_loss -713594.625
wandb:              valid_acc 0.5511
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_120_0m549hek_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/0m549hek
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 113 media file(s), 106 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_110459-0m549hek/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_131458-axpzo6x0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_220_axpzo6x0_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/axpzo6x0
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_120; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_220; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=30, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
Epoch 100 ━╸                                16/274 0:00:01 • 0:00:19 14.31it/s loss: 7.09e+18 v_num: o6x0 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.035 MB uploadedwandb: | 0.015 MB of 0.038 MB uploadedwandb: / 0.015 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:       negative_loss ████████████████████████▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▂▂▂▂▂▂█▆▅▅▇▆▅▄
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████████▇▆▆▆▆▆▆▆▂▁▁▁▁▁▁▂
wandb:    train_loss/total ████████████████████████▇▆▆▆▆▆▆▆▂▁▁▁▁▁▁▂
wandb:      train_step_acc ▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▃▄▄▄▅▅▅▅▄▅▅▅▆▆▆▇▅▆▆▇▇▇██
wandb: trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████████▇▆▆▇▇▇▆▇▃▂▂▃▁▂▂▂
wandb:           valid_acc ▁▁▂▂▂▂▁▂▂▃▃▃▄▃▄▃▂▃▂▄▄▅▄▄▂▄▆▄▃▂▆▄▂▅▅▅█▆▆▅
wandb: 
wandb: Run summary:
wandb:               epoch 99
wandb:       negative_loss -192367.92188
wandb:       positive_loss 13132.35547
wandb:               ratio 80.0
wandb:         rho_sigma_2 6400.0
wandb:               scale 160.0
wandb:   train_loss/island -163392.54688
wandb:    train_loss/total -163392.54688
wandb:      train_step_acc 0.456
wandb: trainer/global_step 22799
wandb:  val_last_step_loss -142599.26562
wandb:           valid_acc 0.2145
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_220_axpzo6x0_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/axpzo6x0
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_131458-axpzo6x0/logs
Global seed set to 2024
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240417_134646-sega4bzo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_320_sega4bzo_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/sega4bzo
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_220; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_320; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-15-10-02-35_VGG --start_at 19
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c100', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=30, onehot=Namespace(type='diagonal')), num_classes=100, optim=Namespace(type='sgd', reset_type='default', kwargs=Namespace(lr=0.1, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=[140, 180]), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=320)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-15-10-02-35_VGG', '--start_at', '19']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mSGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': [140, 180]} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                   
Non-trainable params: 0                                                                                   
Total params: 9.2 M                                                                                       
Total estimated model params size (MB): 36                                                                
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [0m
[31mWARNING:	dreaming images were not flushed by wandb. [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
Epoch 100 ━━                                 12/189 0:00:01 • 0:00:16 11.18it/s loss: 7.5e+20 v_num: 4bzo 
Sleep 10 seconds...
Experiment Exception occurred
Traceback (most recent call last):
  File "/home/ubuntu/continual_dreaming/main_experiments.py", line 66, in main
    logic(args_exp, True, project_name=project_name, run_name=k)
  File "/home/ubuntu/continual_dreaming/latent_dreams.py", line 334, in logic
    trainer.fit(model, datamodule=cl_data_module)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/executor/cl_loop.py", line 751, in advance
    self.custom_advance_f(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1595, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/lightning.py", line 1646, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/optim/sgd.py", line 66, in step
    loss = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 333, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 170, in training_step
    return super().training_step(batch=batch, batch_idx=batch_idx, optimizer_idx=optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_base.py", line 114, in training_step
    return self.training_step_normal(batch["normal"], optimizer_idx)
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_model.py", line 166, in training_step_normal
    loss = self.process_losses_normal(
  File "/home/ubuntu/continual_dreaming/model/overlay/cl_latent_chi.py", line 74, in process_losses_normal
    loss = self._loss_f(latent, y)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 304, in __call__
    super().__call__(input, target, train=train)
  File "/home/ubuntu/continual_dreaming/loss_function/chiLoss.py", line 79, in __call__
    assert not torch.any(torch.isnan(input)), f"Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters \
AssertionError: Input for chi-square loss is NaN. Try changing 'scale' >> 'ratio' hyperparameters or give bigger batch size (for X classes the X * 3.2 batch size should work good).

wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.035 MB uploadedwandb: | 0.030 MB of 0.038 MB uploadedwandb: / 0.030 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:       negative_loss ████████████████████████▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁
wandb:       positive_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▃▂▂▂▂▂█▇▆▆▅▅▅▅
wandb:               ratio ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄████████
wandb:         rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃████████
wandb:               scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   train_loss/island ████████████████████████▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁
wandb:    train_loss/total ████████████████████████▆▆▆▆▆▆▆▆▁▁▁▁▁▁▁▁
wandb:      train_step_acc ▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▃▃▃▄▄▅▅▅▄▅▅▅▆▆▆▇▅▆▆▇▇▇██
wandb: trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  val_last_step_loss ████████████████████████▇▇▇█▆▇▆▆▄▄▂▆▃▁▁▂
wandb:           valid_acc ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▂▂▃▃▄▄▄▅▂▃▃▁▅▄▆▆▂▃▄▂▃▇█▇
wandb: 
wandb: Run summary:
wandb:               epoch 99
wandb:       negative_loss -191527.39062
wandb:       positive_loss 13666.8418
wandb:               ratio 80.0
wandb:         rho_sigma_2 6400.0
wandb:               scale 160.0
wandb:   train_loss/island -167549.375
wandb:    train_loss/total -167549.375
wandb:      train_step_acc 0.45194
wandb: trainer/global_step 15699
wandb:  val_last_step_loss -142171.78125
wandb:           valid_acc 0.2685
wandb: 
wandb: 🚀 View run chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_320_sega4bzo_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG/runs/sega4bzo
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-15-10-02-35_VGG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240417_134646-sega4bzo/logs
End of experiment: chi_sqr_c100_sgd_search_latent_size_30_chi_ratio_10_chi_scale_160_batch_size_320; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
