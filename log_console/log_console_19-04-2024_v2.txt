Global seed set to 2024
wandb: Currently logged in as: 01133344 (cccvb). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240419_172227-vuknkltd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_DLA_vuknkltd_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17/runs/vuknkltd
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Experiments to be run:
* 
-d c10 --model.num_classes 10 --loop.schedule 300 --config.framework_type latent-multitarget --loop.num_loops 1 --loop.train_at 0 --model.optim.type adam --model.optim.kwargs.lr 0.001 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 220 --model.type DLA
* 
-d c10 --model.num_classes 10 --loop.schedule 300 --config.framework_type latent-multitarget --loop.num_loops 1 --loop.train_at 0 --model.optim.type adam --model.optim.kwargs.lr 0.001 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 220 --model.type VGG
* 
-d c10 --model.num_classes 10 --loop.schedule 300 --config.framework_type latent-multitarget --loop.num_loops 1 --loop.train_at 0 --model.optim.type adam --model.optim.kwargs.lr 0.001 --model.sched.type MULTISTEP-SCHED --model.sched.kwargs.gamma 0.1 --datamodule.num_workers 3 --loop.save.root model_save/test --loop.save.model --loop.load.root model_save/test --stat.collect_stats.enable --model.loss.chi.shift_min_distance 0 --model.loss.chi.ratio_gamma 2  --model.loss.chi.ratio_milestones 40 60 80 100 --config.seed 2024  --model.latent.size 10 --model.loss.chi.ratio 10 --model.loss.chi.scale 160 --datamodule.batch_size 220 --model.type custom-resnet34

Running experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_DLA; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-19=06-21-17
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c10', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=10, onehot=Namespace(type='diagonal')), num_classes=10, optim=Namespace(type='adam', reset_type='default', kwargs=Namespace(lr=0.001, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=None), steps=(3,)), norm_lambda=0.0, type='DLA', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-19=06-21-17']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: DLA
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_DLA [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mAdam (
Parameter Group 0
    amsgrad: False
    betas: [0.9, 0.999]
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': None} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ DLA                 │ 32.6 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 32.6 M                                                                                                                                                                
Non-trainable params: 0                                                                                                                                                                 
Total params: 32.6 M                                                                                                                                                                    
Total estimated model params size (MB): 130                                                                                                                                             
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
/home/ubuntu/continual_dreaming/pythonEnv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.001] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': None} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d19-04-2024_h19-45-49_vuknkltd [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 274/274 0:00:27 • 0:00:00 9.87it/s loss: -1.08e+05 v_num: kltd 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.9024999737739563     │
│      test_loss_epoch      │       -91730.109375       │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46 0:00:04 • 0:00:00 30.57it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 10 dimensions.
INFO: Plot model_save/test/ClLatentChi/DLA/model_optim_type-adam/d19-04-2024_h19-45-49_vuknkltd/plots/std-mean_idx10
INFO: Plot model_save/test/ClLatentChi/DLA/model_optim_type-adam/d19-04-2024_h19-45-49_vuknkltd/plots/distance_class_idx10
INFO: Plot model_save/test/ClLatentChi/DLA/model_optim_type-adam/d19-04-2024_h19-45-49_vuknkltd/plots/mean_distance_idx10
INFO: Plot model_save/test/ClLatentChi/DLA/model_optim_type-adam/d19-04-2024_h19-45-49_vuknkltd/plots/mean_dist_matrix_idx10
wandb: - 1.469 MB of 1.469 MB uploadedwandb: \ 1.469 MB of 1.469 MB uploadedwandb: | 1.469 MB of 1.469 MB uploadedwandb: / 1.496 MB of 1.543 MB uploaded (0.004 MB deduped)wandb: - 1.496 MB of 1.543 MB uploaded (0.004 MB deduped)wandb: \ 1.543 MB of 1.543 MB uploaded (0.004 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▆▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▂▁▂▂▂▄▃█▇▅▇█▇▆▃▃▆▂▅▁▁▃▃▃▂▄▇▅▁▂▁▂▂▃
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄███████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃███████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy █▆█▅▃▂▂▃▂▂▁▁
wandb:     stats/collect_loss ▂▄▁▇▆▃▃▂▇▄█▄
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▂▄▁▇▆▃▃▇▄█▄▄▄▅▇▅▄▁▇▃▄▄▆▂▄▁▅▆▅▅▃▅▃▃▄▄▄▅▄▄
wandb:      train_loss/island ███████████▆▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▆▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▁▁▃▄▅▆▆▇▇▇▇████████████████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███▁▁
wandb:     val_last_step_loss ███████████▆▆▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▁▂▃▄▅▆▇▇▇██████████████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -108503.58594
wandb:          positive_loss 111.77716
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.90114
wandb:     stats/collect_loss -92683.46875
wandb:               test_acc 0.9025
wandb:        test_loss_epoch -91730.10938
wandb:         test_loss_step -91102.89844
wandb:      train_loss/island -102890.00781
wandb:       train_loss/total -102890.00781
wandb:         train_step_acc 0.99572
wandb:    trainer/global_step 2420
wandb:     val_last_step_loss -91730.10938
wandb:              valid_acc 0.9025
wandb: 
wandb: 🚀 View run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_DLA_vuknkltd_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17/runs/vuknkltd
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17
wandb: Synced 6 W&B file(s), 17 media file(s), 16 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240419_172227-vuknkltd/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240419_194745-s4t0w17d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_VGG_s4t0w17d_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17/runs/s4t0w17d
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_DLA; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_VGG; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-19=06-21-17
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c10', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=10, onehot=Namespace(type='diagonal')), num_classes=10, optim=Namespace(type='adam', reset_type='default', kwargs=Namespace(lr=0.001, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=None), steps=(3,)), norm_lambda=0.0, type='VGG', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-19=06-21-17']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: VGG
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_VGG [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mAdam (
Parameter Group 0
    amsgrad: False
    betas: [0.9, 0.999]
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': None} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ VGG                 │  9.2 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 9.2 M                                                                                                                                                                 
Non-trainable params: 0                                                                                                                                                                 
Total params: 9.2 M                                                                                                                                                                     
Total estimated model params size (MB): 36                                                                                                                                              
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.001] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': None} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d19-04-2024_h20-42-27_s4t0w17d [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 274/274 0:00:10 • 0:00:00 26.32it/s loss: -1.09e+05 v_num: w17d 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.8895999789237976     │
│      test_loss_epoch      │      -88372.9609375       │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46 0:00:03 • 0:00:00 68.79it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 10 dimensions.
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-adam/d19-04-2024_h20-42-27_s4t0w17d/plots/std-mean_idx10
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-adam/d19-04-2024_h20-42-27_s4t0w17d/plots/distance_class_idx10
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-adam/d19-04-2024_h20-42-27_s4t0w17d/plots/mean_distance_idx10
INFO: Plot model_save/test/ClLatentChi/VGG/model_optim_type-adam/d19-04-2024_h20-42-27_s4t0w17d/plots/mean_dist_matrix_idx10
wandb: - 1.575 MB of 1.575 MB uploadedwandb: \ 1.575 MB of 1.575 MB uploadedwandb: | 1.575 MB of 1.575 MB uploadedwandb: / 1.575 MB of 1.575 MB uploadedwandb: - 1.575 MB of 1.575 MB uploadedwandb: \ 1.575 MB of 1.575 MB uploadedwandb: | 1.602 MB of 1.649 MB uploaded (0.004 MB deduped)wandb: / 1.602 MB of 1.649 MB uploaded (0.004 MB deduped)wandb: - 1.649 MB of 1.649 MB uploaded (0.004 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▆▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▂▂▂▂▃█▄▆▄▄▆▂▃▂▅▂▄▃▂▃▁▂▂▂▂▂▂▄▃▁▁▁
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄███████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃███████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy ▂▃█▇▄▅▄▃▂▁▁▁
wandb:     stats/collect_loss ▃▃▁▄▅▃▄▅█▅▅▄
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▄▄▂▅▆▃▄█▅▅▅▄▅▄▄▃▆▁▅▆▄▅▆▄▅▃▃▆▅▃▄▇▄▅▅▂▅▅▅▄
wandb:      train_loss/island ███████████▆▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▆▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▁▂▃▅▆▇▇▇▇██████████████████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███▁▁
wandb:     val_last_step_loss ███████████▆▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▁▂▄▆▆▇▇████████████████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -109180.5625
wandb:          positive_loss 253.59944
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.88788
wandb:     stats/collect_loss -87007.29688
wandb:               test_acc 0.8896
wandb:        test_loss_epoch -88372.96094
wandb:         test_loss_step -97481.74219
wandb:      train_loss/island -107335.39844
wandb:       train_loss/total -107335.39844
wandb:         train_step_acc 0.99796
wandb:    trainer/global_step 2420
wandb:     val_last_step_loss -88372.96094
wandb:              valid_acc 0.8896
wandb: 
wandb: 🚀 View run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_VGG_s4t0w17d_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17/runs/s4t0w17d
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17
wandb: Synced 6 W&B file(s), 17 media file(s), 16 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240419_194745-s4t0w17d/logs
Global seed set to 2024
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in log_run/wandb/run-20240419_204332-b100ngq0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_custom-resnet34_b100ngq0_latent-multitarget_dull_
wandb: ⭐️ View project at https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17
wandb: 🚀 View run at https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17/runs/b100ngq0
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_VGG; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
Running experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_custom-resnet34; repeat 1/1
Seed used: 2024
[34mINFO: Selected None datasampler [0m
[34m	Input command line: [0m
main_experiments.py --project_name exp_2024-04-19=06-21-17
[34m	Used config: [0m
{'pca_estimate_rank': 6, 'wandb': "Namespace(run=Namespace(folder='log_run/'), watch=Namespace(enable=False, log_freq=1000))", 'config': "Namespace(seed=2024, folder='run_conf/', load=None, export=None, test=Namespace(disable=False), cpu=False, dataset='c10', datasampler_type='none', num_tasks=1, framework_type='latent-multitarget', dream_obj_type=None, select_task_type=None, target_processing_type=None, task_split_type=None, overlay_type=None, split=Namespace(num_classes=None))", 'loop': "Namespace(train_at=[0], save=Namespace(model=True, enable_checkpoint=False, dreams=False, root='model_save/test', layer_stats=False, ignore_config=False), load=Namespace(model=False, dreams=False, root='model_save/test', id=None, name=None, layer_stats=False), num_loops=1, schedule=[300], model=Namespace(reload_at=None, reinit_at=None), weight_reset_sanity_check=False, layer_stats=Namespace(use_at=None, hook_to=None, device='cuda', flush_to_disk=False, type=None), vis=Namespace(layerloss=Namespace(mean_norm=Namespace(use_at=None, hook_to=None, scale=0.001, del_cov_after=False, device='cuda'), grad_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), grad_activ_pruning=Namespace(hook_to=None, use_at=None, percent=0.01, device='cuda'), deep_inversion=Namespace(use_at=None, scale=1.0, scale_file=None, hook_to=None), deep_inversion_target=Namespace(use_at=None, scale=1.0, hook_to=None)), generate_at=False, clear_dataset_at=None, image_reg=Namespace(var=Namespace(use_at=None, scale=2.5e-05), l2=Namespace(use_at=None, coeff=1e-05))))", 'model': "Namespace(latent=Namespace(buffer=Namespace(size_per_class=40), size=10, onehot=Namespace(type='diagonal')), num_classes=10, optim=Namespace(type='adam', reset_type='default', kwargs=Namespace(lr=0.001, gamma=1, momentum=0, dampening=0, weight_decay=0, betas=[0.9, 0.999], amsgrad=False)), sched=Namespace(type='MULTISTEP-SCHED', kwargs=Namespace(gamma=0.1, milestones=None), steps=(3,)), norm_lambda=0.0, type='custom-resnet34', default_weights=False, train_sanity_check=False, layer_replace=Namespace(enable=False), loss=Namespace(chi=Namespace(sigma=0.1, ratio=10.0, scale=160.0, l2=0.001, shift_min_distance=0.0, shift_std_of_mean=15.0, ratio_gamma=2.0, scale_gamma=1.0, ratio_milestones=[40.0, 60.0, 80.0, 100.0], scale_milestones=None, dual=Namespace(inner_scale=1.0, outer_scale=1.0))))", 'datamodule': "Namespace(disable_shuffle=False, num_workers=3, vis=Namespace(num_workers=None, per_target=128, multitarget=Namespace(enable=False, random=False), batch_size=128, optim=Namespace(type='adam', kwargs=Namespace(lr=0.001, betas=[0.9, 0.999], gamma=1, weight_decay=0, amsgrad=False, momentum=0, dampening=0)), sched=Namespace(type=None), threshold=[512], disable_transforms=False, disable_shuffle=False, image_type='pixel', only_vis_at=False, standard_image_size=None, decorrelate=False), test_num_workers=None, val_num_workers=None, batch_size=220)", 'fast_dev_run': 'Namespace(enable=False, batches=30, epochs=1, vis_threshold=[5])', 'stat': 'Namespace(compare_latent=False, disorder_dream=False, limit_plots_to=6, collect_stats=Namespace(enable=True, use_dream_dataset=False), plot_classes=None, disorder=Namespace(sigma=0.0, start_img_val=None), collect=Namespace(latent_buffer=Namespace(enable=False, name=None, cl_idx=None, size=50), single_dream=Namespace(enable=False, sigma=0.0)))', 'Plain args': "['main_experiments.py', '--project_name', 'exp_2024-04-19=06-21-17']"}
[34mSelected configuration:[0m
	SELECT TASK: SELECT-CLASSIC
	TARGET PROCESSING: TARGET-LATENT-SAMPLE-NORMAL-MINIMAL-STD-MULTITARGET
	TASK SPLIT: NO-SPLIT
	DREAM OBJECTIVE: OBJECTIVE-LATENT-LOSSF-MULTITARGET-CREATOR
	MODEL TYPE: custom-resnet34
	OVERLAY TYPE: CL-MODEL-ISLAND [0m
[36mCHI-LOSS: Used buffer: CyclicBufferByClass() [0m
[34mINFO: Generating means shifts [0m
[34mINFO: shift_min_distance '0.0' or shift_std_of_mean '15.0' iss zero. Generating matrix of zeros. [0m
[34mINFO: Generated:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) [0m
[32mINFO: Using loss CHI_LOSS [0m
[32mMODEL TYPE: ClLatentChi_CLModel_CustomResNet34 [0m
[36mVIS: Selected dream image type: pixel [0m
[95mTrain task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[95mValidation task split: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] [0m
[31mFast dev run is False [0m
Files already downloaded and verified
[34mINFO: Created [95m0[34m optim config: [32mAdam (
Parameter Group 0
    amsgrad: False
    betas: [0.9, 0.999]
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
) [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': None} [0m
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                 ┃ Type                ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ train_acc            │ MulticlassAccuracy  │      0 │
│ 1 │ train_acc_dream      │ MulticlassAccuracy  │      0 │
│ 2 │ _valid_accs          │ ModuleDict          │      0 │
│ 3 │ test_acc             │ MulticlassAccuracy  │      0 │
│ 4 │ model                │ CustomResNet34      │ 21.3 M │
│ 5 │ cyclic_latent_buffer │ CyclicBufferByClass │      0 │
│ 6 │ _loss_f              │ ChiLoss             │      0 │
└───┴──────────────────────┴─────────────────────┴────────┘
Trainable params: 21.3 M                                                                                                                                                                
Non-trainable params: 0                                                                                                                                                                 
Total params: 21.3 M                                                                                                                                                                    
Total estimated model params size (MB): 85                                                                                                                                              
[34mSTARTING TASK 0, loop 0 -- classes in task [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[95mSelected task number: 0 [0m
[34mINFO: HOOKING UP NORMAL LOOP [0m
[95mINFO: Selected classes for normal dataloader: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 10.0 to: 20.0 at step: 40 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 20.0 to: 40.0 at step: 60 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 40.0 to: 80.0 at step: 80 [0m
[34mINFO: Scheduler for ChiLoss ratio changed value from: 80.0 to: 160.0 at step: 100 [0m
[34mScheduler restarted at epoch 299 end. Learning rate: [0.001] [0m
[34mINFO: Created [95m0[34m sched config: [32mMultiStepLR
{'gamma': 0.1, 'milestones': None} [0m
[34mENDING TASK 0, loop 0 [0m
[34mINFO: Generated current run name: d19-04-2024_h23-06-51_b100ngq0 [0m
[31mWARNING: At loop 1 selected last epoch per task "300" because list index out of range. [0m
Epoch 299 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 274/274 0:00:28 • 0:00:00 9.85it/s loss: -1.09e+05 v_num: ngq0 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
End of training.
Files already downloaded and verified
[95mINFO: Testing for classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         test_acc          │    0.9176999926567078     │
│      test_loss_epoch      │       -94429.390625       │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46/46 0:00:04 • 0:00:00 31.13it/s  
[34mINFO: COLLECT STATS: Selected normal dataset. [0m
[34mSTATISTICS: Collecting model stats [0m
[34mINFO: Selected None datasampler [0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.

WARNING: Plot 3D only for 3 dimensional space! Found 10 dimensions.
INFO: Plot model_save/test/ClLatentChi/CustomResNet34/model_optim_type-adam/d19-04-2024_h23-06-51_b100ngq0/plots/std-mean_idx10
INFO: Plot model_save/test/ClLatentChi/CustomResNet34/model_optim_type-adam/d19-04-2024_h23-06-51_b100ngq0/plots/distance_class_idx10
INFO: Plot model_save/test/ClLatentChi/CustomResNet34/model_optim_type-adam/d19-04-2024_h23-06-51_b100ngq0/plots/mean_distance_idx10
INFO: Plot model_save/test/ClLatentChi/CustomResNet34/model_optim_type-adam/d19-04-2024_h23-06-51_b100ngq0/plots/mean_dist_matrix_idx10
wandb: - 1.518 MB of 1.518 MB uploadedwandb: \ 1.518 MB of 1.518 MB uploadedwandb: | 1.518 MB of 1.518 MB uploadedwandb: / 1.518 MB of 1.518 MB uploadedwandb: - 1.518 MB of 1.518 MB uploadedwandb: \ 1.518 MB of 1.518 MB uploadedwandb: | 1.544 MB of 1.592 MB uploaded (0.004 MB deduped)wandb: / 1.544 MB of 1.592 MB uploaded (0.004 MB deduped)wandb: - 1.592 MB of 1.592 MB uploaded (0.004 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:          negative_loss ███████████▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          positive_loss ▁▁▁▁▁▁▁▁▂▂▂▂▂▅▃█▆▃▃▂▃▃▁▂▃▂▂▂▁▁▁▃▄▁▁▁▂▁▁▅
wandb:                  ratio ▁▁▁▁▁▁▁▁▂▂▂▄▄███████████████████████████
wandb:            rho_sigma_2 ▁▁▁▁▁▁▁▁▁▁▁▃▃███████████████████████████
wandb:                  scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: stats/collect_accuracy █▂▅▂▂▃▃▃▃▃▂▁
wandb:     stats/collect_loss ▁▇▂▆▅▂▃▃▄▅█▅
wandb:               test_acc ▁
wandb:        test_loss_epoch ▁
wandb:         test_loss_step ▁▇▂▆▅▂▃▅▅█▅▁▃▁▅▅▃▃▆▃▅▄▅▄▄▁▃▄▂▅▄▅▄▄▄▄▄▂▂▃
wandb:      train_loss/island ███████████▆▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train_loss/total ███████████▆▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train_step_acc ▁▁▃▅▆▆▇▇▇███████████████████████████████
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███▁▁
wandb:     val_last_step_loss ███████████▆▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              valid_acc ▁▁▃▄▆▇▇▇████████████████████████████████
wandb: 
wandb: Run summary:
wandb:                  epoch 300
wandb:          negative_loss -109914.4375
wandb:          positive_loss 620.35632
wandb:                  ratio 160.0
wandb:            rho_sigma_2 25600.0
wandb:                  scale 160.0
wandb: stats/collect_accuracy 0.91174
wandb:     stats/collect_loss -91119.84375
wandb:               test_acc 0.9177
wandb:        test_loss_epoch -94429.39062
wandb:         test_loss_step -96478.20312
wandb:      train_loss/island -109903.53125
wandb:       train_loss/total -109903.53125
wandb:         train_step_acc 0.9973
wandb:    trainer/global_step 2420
wandb:     val_last_step_loss -94429.39062
wandb:              valid_acc 0.9177
wandb: 
wandb: 🚀 View run chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_custom-resnet34_b100ngq0_latent-multitarget_dull_ at: https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17/runs/b100ngq0
wandb: ⭐️ View project at: https://wandb.ai/cccvb/exp_2024-04-19%3D06-21-17
wandb: Synced 6 W&B file(s), 17 media file(s), 16 artifact file(s) and 1 other file(s)
wandb: Find logs at: log_run/wandb/run-20240419_204332-b100ngq0/logs
End of experiment: chi_sqr_search_latent_size_10_chi_ratio_10_chi_scale_160_batch_size_220_model_type_custom-resnet34; repeat 1/1
Clearing gpu cache and invoking garbage collector
Done
